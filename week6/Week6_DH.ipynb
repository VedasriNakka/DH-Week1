{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vertical-tutorial",
   "metadata": {},
   "source": [
    "## Week6: Digital Humanities\n",
    "#### Group: Jennifer, Vedasri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "absent-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-folder",
   "metadata": {},
   "source": [
    "### Q1. , it is faster to store the stopwords into a list or a dictionary\n",
    "\n",
    "Time taken to replace dictionary key to value :0.721041202545166's; \n",
    "Time taken to remove the List of stowords:1.6510944366455078's\n",
    "\n",
    "As below observation we observed that removing list of stopwords taking more time then replacing dictionary of key to values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-labor",
   "metadata": {},
   "source": [
    "### Q2. Apply the na√Øve Bayes to solve the spam detection problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "average-bacon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing shape:  (5199, 2)\n",
      "Test shape  :  (361, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>happened here while you were adventuring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ask g or iouri, I've told the story like ten t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Great News! Call FREEFONE 08006344447 to claim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Dont know supports srt i thnk. I think ps3 can...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham           happened here while you were adventuring\n",
       "1   ham  Ask g or iouri, I've told the story like ten t...\n",
       "2   ham                             Sorry, I'll call later\n",
       "3  spam  Great News! Call FREEFONE 08006344447 to claim...\n",
       "4   ham  Dont know supports srt i thnk. I think ps3 can..."
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('corpus/sms_spam.train.csv', delimiter=\",\")\n",
    "print(\"Traing shape: \",train.shape)\n",
    "\n",
    "test = pd.read_csv('corpus/sms_spam.test.csv', delimiter=\",\")\n",
    "print(\"Test shape  : \",test.shape)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-perry",
   "metadata": {},
   "source": [
    "#### Class-wise training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "valued-photographer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.866513\n",
       "spam    0.133487\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-saver",
   "metadata": {},
   "source": [
    "#### Class-wise training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "hollywood-shuttle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.853186\n",
       "spam    0.146814\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-uganda",
   "metadata": {},
   "source": [
    "#### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "increased-wealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\veda\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>hope you are having a good week  just checking in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>k  give back my thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>am also doing in cbe only  but have to pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary 4 star ibiza holiday or  10 000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail  dear dave this is your final notice to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  hope you are having a good week  just checking in\n",
       "1   ham                            k  give back my thanks \n",
       "2   ham        am also doing in cbe only  but have to pay \n",
       "3  spam  complimentary 4 star ibiza holiday or  10 000 ...\n",
       "4  spam  okmail  dear dave this is your final notice to..."
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_punctuation = train.copy()\n",
    "train_punctuation['text'] = train['text'].str.replace('\\W', ' ')\n",
    "\n",
    "train_lower = train_punctuation.copy()\n",
    "train_lower['text'] = train_punctuation['text'].str.lower()\n",
    "train_lower.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "loose-madison",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\veda\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>happened here while you were adventuring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ask g or iouri  i ve told the story like ten t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>sorry  i ll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>great news  call freefone 08006344447 to claim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>dont know supports srt i thnk  i think ps3 can...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham           happened here while you were adventuring\n",
       "1   ham  ask g or iouri  i ve told the story like ten t...\n",
       "2   ham                             sorry  i ll call later\n",
       "3  spam  great news  call freefone 08006344447 to claim...\n",
       "4   ham  dont know supports srt i thnk  i think ps3 can..."
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_punctuation = test.copy()\n",
    "test_punctuation['text'] = test['text'].str.replace('\\W', ' ')\n",
    "\n",
    "test_lower = test_punctuation.copy()\n",
    "test_lower['text'] = test_punctuation['text'].str.lower()\n",
    "test_lower.head(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-designer",
   "metadata": {},
   "source": [
    "#### Calculating time taken to replace the dictionary keys to values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "entitled-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to replace dictionary key to value :0.729041576385498's\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>hope you are having a good week  just checking in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>k  give back my thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>am also doing in cbe only  but have to pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary 4 star ibiza holiday or  10 000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail  dear dave this is your final notice to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  hope you are having a good week  just checking in\n",
       "1   ham                            k  give back my thanks \n",
       "2   ham        am also doing in cbe only  but have to pay \n",
       "3  spam  complimentary 4 star ibiza holiday or  10 000 ...\n",
       "4  spam  okmail  dear dave this is your final notice to..."
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contractions = {\n",
    "\"ain't\": \"aim not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"I had\",\n",
    "\"i'd've\": \"I would have\",\n",
    "\"i'll\": \"I will\",\n",
    "\"i'll've\": \"I will have\",\n",
    "\"i'm\": \"I am\",\n",
    "\"i've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \" she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as \",\n",
    "\"that'd\": \"that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \" we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \" who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \" why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "#print(contractions.get(\"you have\", \"you have\"))\n",
    "\n",
    "train_lower_updated = train_lower.copy()\n",
    "\n",
    "start = time.time()\n",
    "contractions_array = []\n",
    "for i, line in enumerate(train_lower['text']):\n",
    "    tokens_without_contractions = [contractions.get(word, word) for word in line.split(\" \")]\n",
    "    \n",
    "    train_lower_updated['text'][i] = (\" \").join(tokens_without_contractions)\n",
    "end = time.time()\n",
    "total_dict = end - start\n",
    "print(\"Time taken to replace dictionary key to value :{}'s\".format(total_dict))\n",
    "\n",
    "train_lower_updated.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-clerk",
   "metadata": {},
   "source": [
    "#### Calculatin top 30 most occurance in ham and 30 spam features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "hired-companion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>hope you are having a good week just checking in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>k give back my thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>am also doing in cbe only but have to pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary star ibiza holiday or cash needs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail dear dave this is your final notice to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham   hope you are having a good week just checking in\n",
       "1   ham                              k give back my thanks\n",
       "2   ham          am also doing in cbe only but have to pay\n",
       "3  spam  complimentary star ibiza holiday or cash needs...\n",
       "4  spam  okmail dear dave this is your final notice to ..."
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to lower case\n",
    "\n",
    "train_lower_only_word_tokens = train_lower.copy()\n",
    "\n",
    "for i,s in enumerate(train_lower['text']):\n",
    "    only_word_tokens = re.findall(\"[a-z]+\", s, re.I)\n",
    "    train_lower_only_word_tokens['text'][i] =  (\" \").join(only_word_tokens)\n",
    "\n",
    "train_lower_only_word_tokens.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-evans",
   "metadata": {},
   "source": [
    "#### Calculating time taken to remove the words from file of list of string stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "aggregate-employee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to remove the List of stowords:1.650094747543335's\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>hope good week checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>k give back thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>also cbe pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary star ibiza holiday cash needs ur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail dear dave final notice collect tenerife...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham                            hope good week checking\n",
       "1   ham                                 k give back thanks\n",
       "2   ham                                       also cbe pay\n",
       "3  spam  complimentary star ibiza holiday cash needs ur...\n",
       "4  spam  okmail dear dave final notice collect tenerife..."
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stop_words\n",
    "import time\n",
    "\n",
    "stop_words_1 = np.loadtxt('corpus/stopwords.txt', dtype='str')\n",
    "train_remove_stop_words = train_lower_only_word_tokens.copy()\n",
    "\n",
    "start = time.time()\n",
    "for index,sms in enumerate(train_lower_only_word_tokens['text']):\n",
    "    token_without_sw = [word for word in sms.split(\" \") if word not in stop_words_1]\n",
    "    train_remove_stop_words['text'][index] = (\" \").join(token_without_sw)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(\"Time taken to remove the List of stowords:{}'s\".format(total))\n",
    "\n",
    "train_remove_stop_words.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "humanitarian-eclipse",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>hope good week checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>give back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>cbe pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary star ibiza holiday cash urgent c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail dear dave final notice collect tenerife...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham                            hope good week checking\n",
       "1   ham                                          give back\n",
       "2   ham                                            cbe pay\n",
       "3  spam  complimentary star ibiza holiday cash urgent c...\n",
       "4  spam  okmail dear dave final notice collect tenerife..."
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stop words\n",
    "\n",
    "stop_words_2 = np.loadtxt('corpus/StopwordSMART.txt', dtype='str')\n",
    "train_remove_stop_words_2 = train_remove_stop_words.copy()\n",
    "\n",
    "for index, sms in enumerate(train_remove_stop_words['text']):\n",
    "    token_without_sw = [word for word in sms.split(\" \") if  word not in stop_words_2]\n",
    "    train_remove_stop_words_2['text'][index] = (\" \").join(token_without_sw) \n",
    "#print(stop_words_2)\n",
    "train_remove_stop_words_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "special-sherman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of hams in training set:  4505\n",
      "Total no. of Spams in training set: 694\n"
     ]
    }
   ],
   "source": [
    "ham_tokens = train_remove_stop_words_2.loc[train_remove_stop_words_2['type'] == 'ham']\n",
    "print(\"Total no. of hams in training set: \",len(ham_tokens))\n",
    "spam_tokens = train_remove_stop_words_2.loc[train_remove_stop_words_2['type'] == 'spam']\n",
    "print(\"Total no. of Spams in training set:\",len(spam_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "respiratory-decimal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ur', 'call', 'good', 'day', 'love', 'time', 'home', 'lor', 'da', 'dont', 'today', 'back', 'send', 'pls', 'night', 'hey', 'wat', 'dear', 'happy', 'hope', '', 'great', 'give', 'work', 'yeah', 'make', 'im', 'morning', 'phone', 'tomorrow']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "words_all = []\n",
    "\n",
    "for i, words in enumerate(ham_tokens['text']):\n",
    "    total_words = words.split(\" \")\n",
    "    for w in total_words: \n",
    "        words_all.append(w)\n",
    "        \n",
    "words_dict = Counter(words_all)\n",
    "dict_sorted = {k: v for k, v in sorted(words_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "#print(dict_sorted)\n",
    "words_ham_30 = list(dict_sorted.keys())[:30]\n",
    "print(words_ham_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "vietnamese-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['call', 'free', 'txt', 'ur', 'stop', 'mobile', 'text', 'claim', 'reply', 'www', 'prize', 'uk', 'send', 'cash', 'win', 'nokia', 'urgent', 'contact', 'msg', 'tone', 'week', 'service', 'box', 'guaranteed', 'customer', 'ppm', 'mins', 'phone', 'cs', 'chat']\n"
     ]
    }
   ],
   "source": [
    "words_all = []\n",
    "\n",
    "for i, words in enumerate(spam_tokens['text']):\n",
    "    total_words = words.split(\" \")\n",
    "    for w in total_words: \n",
    "        words_all.append(w)\n",
    "        \n",
    "words_dict = Counter(words_all)\n",
    "dict_sorted = {k: v for k, v in sorted(words_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "words_spam_30 = list(dict_sorted.keys())[:30]\n",
    "print(words_spam_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fitting-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(set(words_spam_30).intersection(words_ham_30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-blend",
   "metadata": {},
   "source": [
    "#### Train Naive bays classfier on top 30 ham and top 30 ham words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "literary-argentina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8384"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the vocabulary\n",
    "\n",
    "train_lower['text'] = train_lower['text'].str.split()\n",
    "\n",
    "vocabulary = []\n",
    "for sms in train_lower['text']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "vocabulary = list(set(vocabulary))\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "attractive-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating word counts per test\n",
    "\n",
    "top_60_features = words_spam_30+ words_ham_30\n",
    "word_counts_per_sms = {unique_word: [0] * len(train_lower['text']) for unique_word in top_60_features}\n",
    "\n",
    "#print(train_lower['text'])\n",
    "\n",
    "for index, sms in enumerate(train_lower['text']):\n",
    "    for word in sms:\n",
    "        if word in top_60_features:\n",
    "            word_counts_per_sms[word][index] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "determined-injury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call</th>\n",
       "      <th>free</th>\n",
       "      <th>txt</th>\n",
       "      <th>ur</th>\n",
       "      <th>stop</th>\n",
       "      <th>mobile</th>\n",
       "      <th>text</th>\n",
       "      <th>claim</th>\n",
       "      <th>reply</th>\n",
       "      <th>www</th>\n",
       "      <th>...</th>\n",
       "      <th>hope</th>\n",
       "      <th></th>\n",
       "      <th>great</th>\n",
       "      <th>give</th>\n",
       "      <th>work</th>\n",
       "      <th>yeah</th>\n",
       "      <th>make</th>\n",
       "      <th>im</th>\n",
       "      <th>morning</th>\n",
       "      <th>tomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   call  free  txt  ur  stop  mobile  text  claim  reply  www  ...  hope     \\\n",
       "0     0     0    0   0     0       0     0      0      0    0  ...     1  0   \n",
       "1     0     0    0   0     0       0     0      0      0    0  ...     0  0   \n",
       "2     0     0    0   0     0       0     0      0      0    0  ...     0  0   \n",
       "3     0     0    0   0     0       0     0      0      0    0  ...     0  0   \n",
       "4     1     0    0   0     0       0     0      0      0    0  ...     0  0   \n",
       "\n",
       "   great  give  work  yeah  make  im  morning  tomorrow  \n",
       "0      0     0     0     0     0   0        0         0  \n",
       "1      0     1     0     0     0   0        0         0  \n",
       "2      0     0     0     0     0   0        0         0  \n",
       "3      0     0     0     0     0   0        0         0  \n",
       "4      0     0     0     0     0   0        0         0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation of training set\n",
    "\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "digital-morocco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>call</th>\n",
       "      <th>free</th>\n",
       "      <th>txt</th>\n",
       "      <th>ur</th>\n",
       "      <th>stop</th>\n",
       "      <th>mobile</th>\n",
       "      <th>text</th>\n",
       "      <th>claim</th>\n",
       "      <th>reply</th>\n",
       "      <th>...</th>\n",
       "      <th></th>\n",
       "      <th>great</th>\n",
       "      <th>give</th>\n",
       "      <th>work</th>\n",
       "      <th>yeah</th>\n",
       "      <th>make</th>\n",
       "      <th>im</th>\n",
       "      <th>morning</th>\n",
       "      <th>tomorrow</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hope, you, are, having, a, good, week, just, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[k, give, back, my, thanks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[am, also, doing, in, cbe, only, but, have, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[complimentary, 4, star, ibiza, holiday, or, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[okmail, dear, dave, this, is, your, final, no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  call  free  txt  ur  stop  mobile  text  claim  reply  ...     great  \\\n",
       "0   ham     0     0    0   0     0       0     0      0      0  ...  0      0   \n",
       "1   ham     0     0    0   0     0       0     0      0      0  ...  0      0   \n",
       "2   ham     0     0    0   0     0       0     0      0      0  ...  0      0   \n",
       "3  spam     0     0    0   0     0       0     0      0      0  ...  0      0   \n",
       "4  spam     1     0    0   0     0       0     0      0      0  ...  0      0   \n",
       "\n",
       "   give  work  yeah  make  im  morning  tomorrow  \\\n",
       "0     0     0     0     0   0        0         0   \n",
       "1     1     0     0     0   0        0         0   \n",
       "2     0     0     0     0   0        0         0   \n",
       "3     0     0     0     0   0        0         0   \n",
       "4     0     0     0     0   0        0         0   \n",
       "\n",
       "                                               Words  \n",
       "0  [hope, you, are, having, a, good, week, just, ...  \n",
       "1                        [k, give, back, my, thanks]  \n",
       "2  [am, also, doing, in, cbe, only, but, have, to...  \n",
       "3  [complimentary, 4, star, ibiza, holiday, or, 1...  \n",
       "4  [okmail, dear, dave, this, is, your, final, no...  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatinating Label, text to word-counts\n",
    "\n",
    "training_set_clean = pd.concat([train_lower['type'], word_counts], axis=1)\n",
    "training_set_clean['Words'] = train_lower['text']\n",
    "training_set_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "expressed-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating spam and ham messages first\n",
    "\n",
    "spam_messages = training_set_clean[training_set_clean['type'] == 'spam']\n",
    "ham_messages = training_set_clean[training_set_clean['type'] == 'ham']\n",
    "spam_messages.head(5)\n",
    "\n",
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages) / len(training_set_clean)\n",
    "\n",
    "# # N_Spam\n",
    "n_words_per_spam_message = spam_messages['Words'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "# # N_Ham\n",
    "n_words_per_ham_message = ham_messages['Words'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "# # N_Vocabulary\n",
    "n_vocabulary = len(top_30_features)\n",
    "\n",
    "# # Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "involved-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameters_spam = {unique_word:0 for unique_word in top_60_features}\n",
    "parameters_ham = {unique_word:0 for unique_word in top_60_features}\n",
    "\n",
    "# Calculate parameters\n",
    "for word in top_60_features:\n",
    "    n_word_given_spam = spam_messages[word].sum() \n",
    "    \n",
    "    #print( word, n_word_given_spam )\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "\n",
    "    n_word_given_ham = ham_messages[word].sum() \n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "    parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "wooden-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "    '''\n",
    "    message: a string\n",
    "    '''\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "\n",
    "    p_spam_given_message = np.log(p_spam)\n",
    "    p_ham_given_message = np.log(p_ham)\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "             p_spam_given_message += np.log( parameters_spam[word])\n",
    "\n",
    "        if word in parameters_ham: \n",
    "             p_ham_given_message += np.log(parameters_ham[word])\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    \n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "shared-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "    '''\n",
    "    message: a string\n",
    "    '''\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "\n",
    "    p_spam_given_message = np.log(p_spam)\n",
    "    p_ham_given_message = np.log(p_ham)\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message += np.log( parameters_spam[word])\n",
    "\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message += np.log( parameters_ham[word])\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "corresponding-assets",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>happened here while you were adventuring</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ask g or iouri  i ve told the story like ten t...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>sorry  i ll call later</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>great news  call freefone 08006344447 to claim...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>dont know supports srt i thnk  i think ps3 can...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text predicted\n",
       "0   ham           happened here while you were adventuring       ham\n",
       "1   ham  ask g or iouri  i ve told the story like ten t...       ham\n",
       "2   ham                             sorry  i ll call later       ham\n",
       "3  spam  great news  call freefone 08006344447 to claim...      spam\n",
       "4   ham  dont know supports srt i thnk  i think ps3 can...       ham"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lower['predicted'] = test_lower['text'].apply(classify_test_set)\n",
    "test_lower.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-tolerance",
   "metadata": {},
   "source": [
    "#### Evaluation:\n",
    "As below we have got the accuracy of 95.29% we have removed all punctuations, numbers and spaces. Trained naive bays classifier with top 30 most frequently occurance of ham words and 30 most frequently occurance of spam words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "numeric-enhancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct   : 344/361\n",
      "Incorrect : 17/361\n",
      "Accuracy  : 95.29%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_lower.shape[0]\n",
    "\n",
    "for row in test_lower.iterrows():\n",
    "    row = row[1]\n",
    "    if row['type'] == row['predicted']:\n",
    "        correct += 1\n",
    "\n",
    "print('Correct   : {}/{}'.format(correct, total))\n",
    "print('Incorrect : {}/{}'.format(total-correct, total))\n",
    "print('Accuracy  : {:.2f}%'.format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-elevation",
   "metadata": {},
   "source": [
    "### Apply the na√Øve Bayes to solve the authorship attribution problem related to the Federalist Papers (federalist-papersNew2.csv) with the twelve disputed papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "solved-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special\n",
    "import itertools\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "scientific-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= GaussianNB()\n",
    "le = preprocessing.LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "unauthorized-administrator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upon</th>\n",
       "      <th>to</th>\n",
       "      <th>would</th>\n",
       "      <th>while</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   upon  to  would  while  up\n",
       "1     6  72      2      0   0\n",
       "2     1  53      5      1   0\n",
       "3     0  56      2      0   0\n",
       "4     0  51     17      0   0\n",
       "5     0  45     37      0   0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting all the words of Interest.\n",
    "\n",
    "df = pd.read_csv('corpus/federalist-papersNew2.csv', index_col=0)\n",
    "words_of_interest = ['upon', 'to', 'would','while','up']\n",
    "df[words_of_interest].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "north-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the disputed essays\n",
    "\n",
    "fed = disputed_essays = df[df['AUTHOR'] == 'Hamilton OR Madison'].index\n",
    "assert len(disputed_essays) == 12  # there are twelve disputed essays\n",
    "# numbers widely used to identify the essays\n",
    "assert set(disputed_essays) == {49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 62, 63}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "elect-highlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamilton    51\n",
      "Madison     14\n",
      "Name: AUTHOR, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>109</th>\n",
       "      <th>11</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yourselves</th>\n",
       "      <th>zaleucus</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zelden</th>\n",
       "      <th>AUTHOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows √ó 11501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    000  1  10  100  104  105  109  11  114  115  ...  young  your  yourself  \\\n",
       "1     0  2   0    0    0    0    0   0    0    0  ...      0    10         0   \n",
       "6     0  2   2    0    0    0    0   2    0    0  ...      0     0         0   \n",
       "7     0  1   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "8     0  2   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "9     0  1   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "..  ... ..  ..  ...  ...  ...  ...  ..  ...  ...  ...    ...   ...       ...   \n",
       "81    0  2   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "82    0  1   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "83    0  2   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "84    0  4   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "85    0  2   0    0    0    0    0   0    0    0  ...      0     4         0   \n",
       "\n",
       "    yourselves  zaleucus  zeal  zealand  zealous  zelden    AUTHOR  \n",
       "1            0         0     3        0        0       0  Hamilton  \n",
       "6            0         0     0        0        0       0  Hamilton  \n",
       "7            0         0     1        0        0       0  Hamilton  \n",
       "8            0         0     0        0        0       0  Hamilton  \n",
       "9            0         0     0        0        0       0  Hamilton  \n",
       "..         ...       ...   ...      ...      ...     ...       ...  \n",
       "81           0         0     0        0        0       0  Hamilton  \n",
       "82           0         0     0        0        0       0  Hamilton  \n",
       "83           0         0     0        0        0       0  Hamilton  \n",
       "84           0         0     2        0        0       0  Hamilton  \n",
       "85           0         0     1        0        2       0  Hamilton  \n",
       "\n",
       "[65 rows x 11501 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed = df_known = df.loc[df['AUTHOR'].isin(('Hamilton', 'Madison'))]\n",
    "print(df_known['AUTHOR'].value_counts())\n",
    "fed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "architectural-pattern",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\veda\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upon</th>\n",
       "      <th>would</th>\n",
       "      <th>to</th>\n",
       "      <th>while</th>\n",
       "      <th>up</th>\n",
       "      <th>Author_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>51</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>20</td>\n",
       "      <td>48</td>\n",
       "      <td>219</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    upon  would   to  while  up  Author_Group\n",
       "1      6      2   72      0   0             0\n",
       "6      4      6   58      0   0             0\n",
       "7     11     51   82      0   1             0\n",
       "8      3     27   80      0   3             0\n",
       "9      4      8   71      1   0             0\n",
       "..   ...    ...  ...    ...  ..           ...\n",
       "81    13     21  163      2   1             0\n",
       "82     4     11   83      0   0             0\n",
       "83    20     48  219      4   0             0\n",
       "84    13     18  140      1   1             0\n",
       "85    12      6  115      0   1             0\n",
       "\n",
       "[65 rows x 6 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the 'AUTHOR' to numerical categories using label encoder\n",
    "\n",
    "known_pap=fed[['upon','would','to','while','up','AUTHOR']]\n",
    "\n",
    "known_pap['Author_Group']=le.fit_transform(known_pap['AUTHOR'])\n",
    "known_pap=known_pap.drop('AUTHOR', axis=1)\n",
    "known_pap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "automotive-mailman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>109</th>\n",
       "      <th>11</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yourselves</th>\n",
       "      <th>zaleucus</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zelden</th>\n",
       "      <th>AUTHOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 11501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    000  1  10  100  104  105  109  11  114  115  ...  young  your  yourself  \\\n",
       "49    0  0   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "50    0  0   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "51    0  0   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "52    0  0   0    0    0    0    0   0    0    0  ...      1     0         0   \n",
       "53    0  0   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "\n",
       "    yourselves  zaleucus  zeal  zealand  zealous  zelden               AUTHOR  \n",
       "49           0         0     0        0        0       0  Hamilton OR Madison  \n",
       "50           0         0     0        0        0       0  Hamilton OR Madison  \n",
       "51           0         0     0        0        0       0  Hamilton OR Madison  \n",
       "52           0         0     1        0        0       0  Hamilton OR Madison  \n",
       "53           0         0     1        0        0       0  Hamilton OR Madison  \n",
       "\n",
       "[5 rows x 11501 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disputed_essays = df[df['AUTHOR'] == 'Hamilton OR Madison']\n",
    "disputed_essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "healthy-murray",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upon</th>\n",
       "      <th>would</th>\n",
       "      <th>to</th>\n",
       "      <th>while</th>\n",
       "      <th>up</th>\n",
       "      <th>AUTHOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    upon  would  to  while  up               AUTHOR\n",
       "49     0     22  58      0   0  Hamilton OR Madison\n",
       "50     1     11  28      0   0  Hamilton OR Madison\n",
       "51     0      9  50      0   0  Hamilton OR Madison\n",
       "52     0      8  72      0   0  Hamilton OR Madison\n",
       "53     0      6  73      0   0  Hamilton OR Madison\n",
       "54     2      6  61      0   0  Hamilton OR Madison\n",
       "55     0     10  78      0   1  Hamilton OR Madison\n",
       "56     0      4  39      0   0  Hamilton OR Madison\n",
       "57     0      6  74      0   0  Hamilton OR Madison\n",
       "58     0     12  61      0   0  Hamilton OR Madison\n",
       "62     0      5  82      0   0  Hamilton OR Madison\n",
       "63     0     11  88      0   2  Hamilton OR Madison"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting the test dataset for only the 'words_of_interest'\n",
    "\n",
    "disp_essays=disputed_essays[['upon','would','to','while','up','AUTHOR']]\n",
    "disp_essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "revised-carpet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upon</th>\n",
       "      <th>would</th>\n",
       "      <th>to</th>\n",
       "      <th>while</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    upon  would  to  while  up\n",
       "49     0     22  58      0   0\n",
       "50     1     11  28      0   0\n",
       "51     0      9  50      0   0\n",
       "52     0      8  72      0   0\n",
       "53     0      6  73      0   0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_essay_test=disp_essays.drop('AUTHOR',axis=1)\n",
    "\n",
    "\n",
    "disp_essay_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-landscape",
   "metadata": {},
   "source": [
    "#### Naive Bayes Model Algorithm:\n",
    "\n",
    "1. Calculate prior for all catergories of the Output(Hamilton or Madison)\n",
    "        --prior(Hamilton) = sum(essays by Hamilton)/ sum(all essays)\n",
    "        --prior(Madison) = sum(essays by Hamilton)/ sum(all essays)\n",
    "2. Calculate the conditional probability for each category for each attribute for all the test samples\n",
    "        -- alpha=1 - using Laplace smoothing\n",
    "        -- Prob(word|Hamilton)= sum(word occurence)+ alpha/ (sum (all word occurence)+ no.of attributes considered)\n",
    "3. Sum the log of conditional probability and prior for each catergory\n",
    "        --posterior = log (prior)+ Sum(log(Prob of word|Hamilton)\n",
    "4. Obtain the argmax for the posterior:\n",
    "        -- and append to the y_pred- the chosen category for the selected test example.\n",
    "5. Repeat steps for each test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "champion-buyer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prior(df,Y):\n",
    "    classes= df[Y].unique()\n",
    "    prior=[]\n",
    "    for category in classes:\n",
    "        prior.append(len(df[df[Y]==category])/len(df))\n",
    "        #print(prior)\n",
    "    return prior\n",
    "def conditional_probability(df,feat_name,feat_val,Y,label):\n",
    "    feat=list(df.columns)\n",
    "    df=df[df[Y]==label]\n",
    "    alpha=1\n",
    "    num= df[feat_name].sum()+1\n",
    "    dem=np.sum(df.sum(),axis=0)+feat_val\n",
    "   # print('prob= ',num/dem)\n",
    "    \n",
    "    return np.log(num/dem)\n",
    "\n",
    "def naive_bayes(df,X_test,Category):\n",
    "    features= list(df.columns)[:-1]\n",
    "    classes=df[Category].unique()\n",
    "    priors=[]\n",
    "    priors=prior(df,Category)\n",
    "    #print(priors)\n",
    "    Y_pred=[]\n",
    "    \n",
    "    for x in range(len(X_test)):\n",
    "       # print('value x=  ',x)\n",
    "       \n",
    "        classes=list(df[Category].unique())\n",
    "        posteriors=[]\n",
    "        \n",
    "        for i in range((len(classes))):\n",
    "            posterior=0\n",
    "            \n",
    "            cond_prob=0\n",
    "            for j in range(len(features)):\n",
    "                count=X_test.iloc[x].loc[features[j]]\n",
    "               # print(cond_prob,'features :=',features[j], x,count)\n",
    "                cond_prob+=count*conditional_probability(df,features[j],len(features),Category,classes[i])\n",
    "            posterior=np.log(priors[i])+cond_prob\n",
    "           \n",
    "            posteriors.append(posterior)\n",
    "            #print('posteriors',posteriors)\n",
    "        Y_pred.append(np.argmax(posteriors))\n",
    "    return np.array(Y_pred)\n",
    "\n",
    "\n",
    "df=known_pap    \n",
    "X_test=disp_essay_test\n",
    "naive_bayes(df,X_test,Category='Author_Group')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd1a1e9",
   "metadata": {},
   "source": [
    "Using the above mentioned algorithm we are unable to obtain 100% accuracy, but 8 out of 11 essays written by Madison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca32927",
   "metadata": {},
   "source": [
    "### Using Naive bayes classifier in Scikit:\n",
    "We can observe that all the disputed essays are written by Madison =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "incomplete-identity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=known_pap[['upon','would','to','while','up']]\n",
    "Y_train=known_pap['Author_Group']\n",
    "X_test=disp_essay_test\n",
    "clf.fit(X_train,Y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-taste",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
