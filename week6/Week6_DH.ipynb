{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vertical-tutorial",
   "metadata": {},
   "source": [
    "## Week6: Digital Humanities\n",
    "#### Group: Jennifer, Vedasri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "absent-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-folder",
   "metadata": {},
   "source": [
    "### Q1. , it is faster to store the stopwords into a list or a dictionary\n",
    "\n",
    "Time taken to replace dictionary key to value :0.721041202545166's\n",
    "\n",
    "Time taken to remove the List of stowords:1.6510944366455078's\n",
    "\n",
    "As below observation we observed that removing list of stopwords taking more time then replacing dictionary of key to values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-labor",
   "metadata": {},
   "source": [
    "### Q2. Apply the na√Øve Bayes to solve the spam detection problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "average-bacon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing shape:  (5199, 2)\n",
      "Test shape  :  (361, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>happened here while you were adventuring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ask g or iouri, I've told the story like ten t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Great News! Call FREEFONE 08006344447 to claim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Dont know supports srt i thnk. I think ps3 can...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham           happened here while you were adventuring\n",
       "1   ham  Ask g or iouri, I've told the story like ten t...\n",
       "2   ham                             Sorry, I'll call later\n",
       "3  spam  Great News! Call FREEFONE 08006344447 to claim...\n",
       "4   ham  Dont know supports srt i thnk. I think ps3 can..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('corpus/sms_spam.train.csv', delimiter=\",\")\n",
    "print(\"Traing shape: \",train.shape)\n",
    "\n",
    "test = pd.read_csv('corpus/sms_spam.test.csv', delimiter=\",\")\n",
    "print(\"Test shape  : \",test.shape)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-perry",
   "metadata": {},
   "source": [
    "#### Class-wise training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "valued-photographer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.866513\n",
       "spam    0.133487\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-saver",
   "metadata": {},
   "source": [
    "#### Class-wise training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "hollywood-shuttle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.853186\n",
       "spam    0.146814\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-uganda",
   "metadata": {},
   "source": [
    "#### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "increased-wealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\veda\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>hope you are having a good week  just checking in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>k  give back my thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>am also doing in cbe only  but have to pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary 4 star ibiza holiday or  10 000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail  dear dave this is your final notice to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  hope you are having a good week  just checking in\n",
       "1   ham                            k  give back my thanks \n",
       "2   ham        am also doing in cbe only  but have to pay \n",
       "3  spam  complimentary 4 star ibiza holiday or  10 000 ...\n",
       "4  spam  okmail  dear dave this is your final notice to..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_punctuation = train.copy()\n",
    "train_punctuation['text'] = train['text'].str.replace('\\W', ' ')\n",
    "\n",
    "train_lower = train_punctuation.copy()\n",
    "train_lower['text'] = train_punctuation['text'].str.lower()\n",
    "train_lower.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "loose-madison",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\veda\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>happened here while you were adventuring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ask g or iouri  i ve told the story like ten t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>sorry  i ll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>great news  call freefone 08006344447 to claim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>dont know supports srt i thnk  i think ps3 can...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham           happened here while you were adventuring\n",
       "1   ham  ask g or iouri  i ve told the story like ten t...\n",
       "2   ham                             sorry  i ll call later\n",
       "3  spam  great news  call freefone 08006344447 to claim...\n",
       "4   ham  dont know supports srt i thnk  i think ps3 can..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_punctuation = test.copy()\n",
    "test_punctuation['text'] = test['text'].str.replace('\\W', ' ')\n",
    "\n",
    "test_lower = test_punctuation.copy()\n",
    "test_lower['text'] = test_punctuation['text'].str.lower()\n",
    "test_lower.head(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-designer",
   "metadata": {},
   "source": [
    "#### Calculating time taken to replace the dictionary keys to values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "entitled-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to replace dictionary key to value :0.7170407772064209's\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>hope you are having a good week  just checking in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>k  give back my thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>am also doing in cbe only  but have to pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary 4 star ibiza holiday or  10 000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail  dear dave this is your final notice to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  hope you are having a good week  just checking in\n",
       "1   ham                            k  give back my thanks \n",
       "2   ham        am also doing in cbe only  but have to pay \n",
       "3  spam  complimentary 4 star ibiza holiday or  10 000 ...\n",
       "4  spam  okmail  dear dave this is your final notice to..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contractions = {\n",
    "\"ain't\": \"aim not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"I had\",\n",
    "\"i'd've\": \"I would have\",\n",
    "\"i'll\": \"I will\",\n",
    "\"i'll've\": \"I will have\",\n",
    "\"i'm\": \"I am\",\n",
    "\"i've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \" she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as \",\n",
    "\"that'd\": \"that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \" we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \" who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \" why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "#print(contractions.get(\"you have\", \"you have\"))\n",
    "\n",
    "train_lower_updated = train_lower.copy()\n",
    "\n",
    "start = time.time()\n",
    "contractions_array = []\n",
    "for i, line in enumerate(train_lower['text']):\n",
    "    tokens_without_contractions = [contractions.get(word, word) for word in line.split(\" \")]\n",
    "    \n",
    "    train_lower_updated['text'][i] = (\" \").join(tokens_without_contractions)\n",
    "end = time.time()\n",
    "total_dict = end - start\n",
    "print(\"Time taken to replace dictionary key to value :{}'s\".format(total_dict))\n",
    "\n",
    "train_lower_updated.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-clerk",
   "metadata": {},
   "source": [
    "#### Calculatin top 30 most occurance in ham and 30 spam features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "hired-companion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>hope you are having a good week just checking in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>k give back my thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>am also doing in cbe only but have to pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary star ibiza holiday or cash needs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail dear dave this is your final notice to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham   hope you are having a good week just checking in\n",
       "1   ham                              k give back my thanks\n",
       "2   ham          am also doing in cbe only but have to pay\n",
       "3  spam  complimentary star ibiza holiday or cash needs...\n",
       "4  spam  okmail dear dave this is your final notice to ..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to lower case\n",
    "\n",
    "train_lower_only_word_tokens = train_lower.copy()\n",
    "\n",
    "for i,s in enumerate(train_lower['text']):\n",
    "    only_word_tokens = re.findall(\"[a-z]+\", s, re.I)\n",
    "    train_lower_only_word_tokens['text'][i] =  (\" \").join(only_word_tokens)\n",
    "\n",
    "train_lower_only_word_tokens.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-evans",
   "metadata": {},
   "source": [
    "#### Calculating time taken to remove the words from file of list of string stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aggregate-employee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to remove the List of stowords:1.5970911979675293's\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>hope good week checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>k give back thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>also cbe pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary star ibiza holiday cash needs ur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail dear dave final notice collect tenerife...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham                            hope good week checking\n",
       "1   ham                                 k give back thanks\n",
       "2   ham                                       also cbe pay\n",
       "3  spam  complimentary star ibiza holiday cash needs ur...\n",
       "4  spam  okmail dear dave final notice collect tenerife..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stop_words\n",
    "import time\n",
    "\n",
    "stop_words_1 = np.loadtxt('corpus/stopwords.txt', dtype='str')\n",
    "train_remove_stop_words = train_lower_only_word_tokens.copy()\n",
    "\n",
    "start = time.time()\n",
    "for index,sms in enumerate(train_lower_only_word_tokens['text']):\n",
    "    token_without_sw = [word for word in sms.split(\" \") if word not in stop_words_1]\n",
    "    train_remove_stop_words['text'][index] = (\" \").join(token_without_sw)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(\"Time taken to remove the List of stowords:{}'s\".format(total))\n",
    "\n",
    "train_remove_stop_words.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "humanitarian-eclipse",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a' \"a's\" 'able' 'about' 'above' 'according' 'accordingly' 'across'\n",
      " 'actually' 'after' 'afterwards' 'again' 'against' \"ain't\" 'all' 'allow'\n",
      " 'allows' 'almost' 'alone' 'along' 'already' 'also' 'although' 'always'\n",
      " 'am' 'among' 'amongst' 'an' 'and' 'another' 'any' 'anybody' 'anyhow'\n",
      " 'anyone' 'anything' 'anyway' 'anyways' 'anywhere' 'apart' 'appear'\n",
      " 'appreciate' 'appropriate' 'are' \"aren't\" 'around' 'as' 'aside' 'ask'\n",
      " 'asking' 'associated' 'at' 'available' 'away' 'awfully' 'b' 'be' 'became'\n",
      " 'because' 'become' 'becomes' 'becoming' 'been' 'before' 'beforehand'\n",
      " 'behind' 'being' 'believe' 'below' 'beside' 'besides' 'best' 'better'\n",
      " 'between' 'beyond' 'both' 'brief' 'but' 'by' 'c' \"c'mon\" \"c's\" 'came'\n",
      " 'can' \"can't\" 'cannot' 'cant' 'cause' 'causes' 'certain' 'certainly'\n",
      " 'changes' 'clearly' 'co' 'com' 'come' 'comes' 'concerning' 'consequently'\n",
      " 'consider' 'considering' 'contain' 'containing' 'contains'\n",
      " 'corresponding' 'could' \"couldn't\" 'course' 'currently' 'd' 'definitely'\n",
      " 'described' 'despite' 'did' \"didn't\" 'different' 'do' 'does' \"doesn't\"\n",
      " 'doing' \"don't\" 'done' 'down' 'downwards' 'during' 'e' 'each' 'edu' 'eg'\n",
      " 'eight' 'either' 'else' 'elsewhere' 'enough' 'entirely' 'especially' 'et'\n",
      " 'etc' 'even' 'ever' 'every' 'everybody' 'everyone' 'everything'\n",
      " 'everywhere' 'ex' 'exactly' 'example' 'except' 'f' 'far' 'few' 'fifth'\n",
      " 'first' 'five' 'followed' 'following' 'follows' 'for' 'former' 'formerly'\n",
      " 'forth' 'four' 'from' 'further' 'furthermore' 'g' 'get' 'gets' 'getting'\n",
      " 'given' 'gives' 'go' 'goes' 'going' 'gone' 'got' 'gotten' 'greetings' 'h'\n",
      " 'had' \"hadn't\" 'happens' 'hardly' 'has' \"hasn't\" 'have' \"haven't\"\n",
      " 'having' 'he' \"he's\" 'hello' 'help' 'hence' 'her' 'here' \"here's\"\n",
      " 'hereafter' 'hereby' 'herein' 'hereupon' 'hers' 'herself' 'hi' 'him'\n",
      " 'himself' 'his' 'hither' 'hopefully' 'how' 'howbeit' 'however' 'i' \"i'd\"\n",
      " \"i'll\" \"i'm\" \"i've\" 'ie' 'if' 'ignored' 'immediate' 'in' 'inasmuch' 'inc'\n",
      " 'indeed' 'indicate' 'indicated' 'indicates' 'inner' 'insofar' 'instead'\n",
      " 'into' 'inward' 'is' \"isn't\" 'it' \"it'd\" \"it'll\" \"it's\" 'its' 'itself'\n",
      " 'j' 'just' 'k' 'keep' 'keeps' 'kept' 'know' 'knows' 'known' 'l' 'last'\n",
      " 'lately' 'later' 'latter' 'latterly' 'least' 'less' 'lest' 'let' \"let's\"\n",
      " 'like' 'liked' 'likely' 'little' 'look' 'looking' 'looks' 'ltd' 'm'\n",
      " 'mainly' 'many' 'may' 'maybe' 'me' 'mean' 'meanwhile' 'merely' 'might'\n",
      " 'more' 'moreover' 'most' 'mostly' 'much' 'must' 'my' 'myself' 'n' 'name'\n",
      " 'namely' 'nd' 'near' 'nearly' 'necessary' 'need' 'needs' 'neither'\n",
      " 'never' 'nevertheless' 'new' 'next' 'nine' 'no' 'nobody' 'non' 'none'\n",
      " 'noone' 'nor' 'normally' 'not' 'nothing' 'novel' 'now' 'nowhere' 'o'\n",
      " 'obviously' 'of' 'off' 'often' 'oh' 'ok' 'okay' 'old' 'on' 'once' 'one'\n",
      " 'ones' 'only' 'onto' 'or' 'other' 'others' 'otherwise' 'ought' 'our'\n",
      " 'ours' 'ourselves' 'out' 'outside' 'over' 'overall' 'own' 'p'\n",
      " 'particular' 'particularly' 'per' 'perhaps' 'placed' 'please' 'plus'\n",
      " 'possible' 'presumably' 'probably' 'provides' 'q' 'que' 'quite' 'r'\n",
      " 'rather' 'rd' 're' 'really' 'reasonably' 'regarding' 'regardless'\n",
      " 'regards' 'relatively' 'respectively' 'right' 's' 'said' 'same' 'saw'\n",
      " 'say' 'saying' 'says' 'second' 'secondly' 'see' 'seeing' 'seem' 'seemed'\n",
      " 'seeming' 'seems' 'seen' 'self' 'selves' 'sensible' 'sent' 'serious'\n",
      " 'seriously' 'seven' 'several' 'shall' 'she' 'should' \"shouldn't\" 'since'\n",
      " 'six' 'so' 'some' 'somebody' 'somehow' 'someone' 'something' 'sometime'\n",
      " 'sometimes' 'somewhat' 'somewhere' 'soon' 'sorry' 'specified' 'specify'\n",
      " 'specifying' 'still' 'sub' 'such' 'sup' 'sure' 't' \"t's\" 'take' 'taken'\n",
      " 'tell' 'tends' 'th' 'than' 'thank' 'thanks' 'thanx' 'that' \"that's\"\n",
      " 'thats' 'the' 'their' 'theirs' 'them' 'themselves' 'then' 'thence'\n",
      " 'there' \"there's\" 'thereafter' 'thereby' 'therefore' 'therein' 'theres'\n",
      " 'thereupon' 'these' 'they' \"they'd\" \"they'll\" \"they're\" \"they've\" 'think'\n",
      " 'third' 'this' 'thorough' 'thoroughly' 'those' 'though' 'three' 'through'\n",
      " 'throughout' 'thru' 'thus' 'to' 'together' 'too' 'took' 'toward'\n",
      " 'towards' 'tried' 'tries' 'truly' 'try' 'trying' 'twice' 'two' 'u' 'un'\n",
      " 'under' 'unfortunately' 'unless' 'unlikely' 'until' 'unto' 'up' 'upon'\n",
      " 'us' 'use' 'used' 'useful' 'uses' 'using' 'usually' 'uucp' 'v' 'value'\n",
      " 'various' 'very' 'via' 'viz' 'vs' 'w' 'want' 'wants' 'was' \"wasn't\" 'way'\n",
      " 'we' \"we'd\" \"we'll\" \"we're\" \"we've\" 'welcome' 'well' 'went' 'were'\n",
      " \"weren't\" 'what' \"what's\" 'whatever' 'when' 'whence' 'whenever' 'where'\n",
      " \"where's\" 'whereafter' 'whereas' 'whereby' 'wherein' 'whereupon'\n",
      " 'wherever' 'whether' 'which' 'while' 'whither' 'who' \"who's\" 'whoever'\n",
      " 'whole' 'whom' 'whose' 'why' 'will' 'willing' 'wish' 'with' 'within'\n",
      " 'without' \"won't\" 'wonder' 'would' 'would' \"wouldn't\" 'x' 'y' 'yes' 'yet'\n",
      " 'you' \"you'd\" \"you'll\" \"you're\" \"you've\" 'your' 'yours' 'yourself'\n",
      " 'yourselves' 'z' 'zero']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>hope good week checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>give back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>cbe pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary star ibiza holiday cash urgent c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail dear dave final notice collect tenerife...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham                            hope good week checking\n",
       "1   ham                                          give back\n",
       "2   ham                                            cbe pay\n",
       "3  spam  complimentary star ibiza holiday cash urgent c...\n",
       "4  spam  okmail dear dave final notice collect tenerife..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stop words\n",
    "\n",
    "stop_words_2 = np.loadtxt('corpus/StopwordSMART.txt', dtype='str')\n",
    "train_remove_stop_words_2 = train_remove_stop_words.copy()\n",
    "\n",
    "for index, sms in enumerate(train_remove_stop_words['text']):\n",
    "    token_without_sw = [word for word in sms.split(\" \") if  word not in stop_words_2]\n",
    "    train_remove_stop_words_2['text'][index] = (\" \").join(token_without_sw) \n",
    "print(stop_words_2)\n",
    "train_remove_stop_words_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "special-sherman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of hams in training set:  4505\n",
      "Total no. of Spams in training set: 694\n"
     ]
    }
   ],
   "source": [
    "ham_tokens = train_remove_stop_words_2.loc[train_remove_stop_words_2['type'] == 'ham']\n",
    "print(\"Total no. of hams in training set: \",len(ham_tokens))\n",
    "spam_tokens = train_remove_stop_words_2.loc[train_remove_stop_words_2['type'] == 'spam']\n",
    "print(\"Total no. of Spams in training set:\",len(spam_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "respiratory-decimal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ur', 'call', 'good', 'day', 'love', 'time', 'home', 'lor', 'da', 'dont', 'today', 'back', 'send', 'pls', 'night', 'hey', 'wat', 'dear', 'happy', 'hope', '', 'great', 'give', 'work', 'yeah', 'make', 'im', 'morning', 'phone', 'tomorrow']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "words_all = []\n",
    "\n",
    "for i, words in enumerate(ham_tokens['text']):\n",
    "    total_words = words.split(\" \")\n",
    "    for w in total_words: \n",
    "        words_all.append(w)\n",
    "        \n",
    "words_dict = Counter(words_all)\n",
    "dict_sorted = {k: v for k, v in sorted(words_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "#print(dict_sorted)\n",
    "words_ham_30 = list(dict_sorted.keys())[:30]\n",
    "print(words_ham_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "vietnamese-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['call', 'free', 'txt', 'ur', 'stop', 'mobile', 'text', 'claim', 'reply', 'www', 'prize', 'uk', 'send', 'cash', 'win', 'nokia', 'urgent', 'contact', 'msg', 'tone', 'week', 'service', 'box', 'guaranteed', 'customer', 'ppm', 'mins', 'phone', 'cs', 'chat']\n"
     ]
    }
   ],
   "source": [
    "words_all = []\n",
    "\n",
    "for i, words in enumerate(spam_tokens['text']):\n",
    "    total_words = words.split(\" \")\n",
    "    for w in total_words: \n",
    "        words_all.append(w)\n",
    "        \n",
    "words_dict = Counter(words_all)\n",
    "dict_sorted = {k: v for k, v in sorted(words_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "words_spam_30 = list(dict_sorted.keys())[:30]\n",
    "print(words_spam_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fitting-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(set(words_spam_30).intersection(words_ham_30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-blend",
   "metadata": {},
   "source": [
    "#### Train Naive bays classfier on top 30 ham and top 30 ham words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "literary-argentina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8384"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the vocabulary\n",
    "\n",
    "train_lower['text'] = train_lower['text'].str.split()\n",
    "\n",
    "vocabulary = []\n",
    "for sms in train_lower['text']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "vocabulary = list(set(vocabulary))\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "attractive-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating word counts per test\n",
    "\n",
    "top_30_features = words_spam_30+ words_ham_30\n",
    "word_counts_per_sms = {unique_word: [0] * len(train_lower['text']) for unique_word in top_30_features}\n",
    "\n",
    "#print(train_lower['text'])\n",
    "\n",
    "for index, sms in enumerate(train_lower['text']):\n",
    "    for word in sms:\n",
    "        if word in top_30_features:\n",
    "            word_counts_per_sms[word][index] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "determined-injury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call</th>\n",
       "      <th>free</th>\n",
       "      <th>txt</th>\n",
       "      <th>ur</th>\n",
       "      <th>stop</th>\n",
       "      <th>mobile</th>\n",
       "      <th>text</th>\n",
       "      <th>claim</th>\n",
       "      <th>reply</th>\n",
       "      <th>www</th>\n",
       "      <th>...</th>\n",
       "      <th>hope</th>\n",
       "      <th></th>\n",
       "      <th>great</th>\n",
       "      <th>give</th>\n",
       "      <th>work</th>\n",
       "      <th>yeah</th>\n",
       "      <th>make</th>\n",
       "      <th>im</th>\n",
       "      <th>morning</th>\n",
       "      <th>tomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   call  free  txt  ur  stop  mobile  text  claim  reply  www  ...  hope     \\\n",
       "0     0     0    0   0     0       0     0      0      0    0  ...     1  0   \n",
       "1     0     0    0   0     0       0     0      0      0    0  ...     0  0   \n",
       "2     0     0    0   0     0       0     0      0      0    0  ...     0  0   \n",
       "3     0     0    0   0     0       0     0      0      0    0  ...     0  0   \n",
       "4     1     0    0   0     0       0     0      0      0    0  ...     0  0   \n",
       "\n",
       "   great  give  work  yeah  make  im  morning  tomorrow  \n",
       "0      0     0     0     0     0   0        0         0  \n",
       "1      0     1     0     0     0   0        0         0  \n",
       "2      0     0     0     0     0   0        0         0  \n",
       "3      0     0     0     0     0   0        0         0  \n",
       "4      0     0     0     0     0   0        0         0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation of training set\n",
    "\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "digital-morocco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>call</th>\n",
       "      <th>free</th>\n",
       "      <th>txt</th>\n",
       "      <th>ur</th>\n",
       "      <th>stop</th>\n",
       "      <th>mobile</th>\n",
       "      <th>text</th>\n",
       "      <th>claim</th>\n",
       "      <th>reply</th>\n",
       "      <th>...</th>\n",
       "      <th></th>\n",
       "      <th>great</th>\n",
       "      <th>give</th>\n",
       "      <th>work</th>\n",
       "      <th>yeah</th>\n",
       "      <th>make</th>\n",
       "      <th>im</th>\n",
       "      <th>morning</th>\n",
       "      <th>tomorrow</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hope, you, are, having, a, good, week, just, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[k, give, back, my, thanks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[am, also, doing, in, cbe, only, but, have, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[complimentary, 4, star, ibiza, holiday, or, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[okmail, dear, dave, this, is, your, final, no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  call  free  txt  ur  stop  mobile  text  claim  reply  ...     great  \\\n",
       "0   ham     0     0    0   0     0       0     0      0      0  ...  0      0   \n",
       "1   ham     0     0    0   0     0       0     0      0      0  ...  0      0   \n",
       "2   ham     0     0    0   0     0       0     0      0      0  ...  0      0   \n",
       "3  spam     0     0    0   0     0       0     0      0      0  ...  0      0   \n",
       "4  spam     1     0    0   0     0       0     0      0      0  ...  0      0   \n",
       "\n",
       "   give  work  yeah  make  im  morning  tomorrow  \\\n",
       "0     0     0     0     0   0        0         0   \n",
       "1     1     0     0     0   0        0         0   \n",
       "2     0     0     0     0   0        0         0   \n",
       "3     0     0     0     0   0        0         0   \n",
       "4     0     0     0     0   0        0         0   \n",
       "\n",
       "                                               Words  \n",
       "0  [hope, you, are, having, a, good, week, just, ...  \n",
       "1                        [k, give, back, my, thanks]  \n",
       "2  [am, also, doing, in, cbe, only, but, have, to...  \n",
       "3  [complimentary, 4, star, ibiza, holiday, or, 1...  \n",
       "4  [okmail, dear, dave, this, is, your, final, no...  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatinating Label, text to word-counts\n",
    "\n",
    "training_set_clean = pd.concat([train_lower['type'], word_counts], axis=1)\n",
    "training_set_clean['Words'] = train_lower['text']\n",
    "training_set_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "expressed-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating spam and ham messages first\n",
    "\n",
    "spam_messages = training_set_clean[training_set_clean['type'] == 'spam']\n",
    "ham_messages = training_set_clean[training_set_clean['type'] == 'ham']\n",
    "spam_messages.head(5)\n",
    "\n",
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages) / len(training_set_clean)\n",
    "\n",
    "# # N_Spam\n",
    "n_words_per_spam_message = spam_messages['Words'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "# # N_Ham\n",
    "n_words_per_ham_message = ham_messages['Words'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "# # N_Vocabulary\n",
    "n_vocabulary = len(top_30_features)\n",
    "\n",
    "# # Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "involved-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameters_spam = {unique_word:0 for unique_word in top_30_features}\n",
    "parameters_ham = {unique_word:0 for unique_word in top_30_features}\n",
    "\n",
    "# Calculate parameters\n",
    "for word in top_30_features:\n",
    "    n_word_given_spam = spam_messages[word].sum() # spam_messages already defined\n",
    "    \n",
    "    #print( word, n_word_given_spam )\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "\n",
    "    n_word_given_ham = ham_messages[word].sum() # ham_messages already defined\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "    parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "wooden-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "    '''\n",
    "    message: a string\n",
    "    '''\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "             p_spam_given_message *= parameters_spam[word]\n",
    "\n",
    "        if word in parameters_ham: \n",
    "             p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    \n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "shared-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "    '''\n",
    "    message: a string\n",
    "    '''\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "corresponding-assets",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>happened here while you were adventuring</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ask g or iouri  i ve told the story like ten t...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>sorry  i ll call later</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>great news  call freefone 08006344447 to claim...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>dont know supports srt i thnk  i think ps3 can...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text predicted\n",
       "0   ham           happened here while you were adventuring       ham\n",
       "1   ham  ask g or iouri  i ve told the story like ten t...       ham\n",
       "2   ham                             sorry  i ll call later       ham\n",
       "3  spam  great news  call freefone 08006344447 to claim...      spam\n",
       "4   ham  dont know supports srt i thnk  i think ps3 can...       ham"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lower['predicted'] = test_lower['text'].apply(classify_test_set)\n",
    "test_lower.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "numeric-enhancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct   : 344/361\n",
      "Incorrect : 17/361\n",
      "Accuracy  : 95.29%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_lower.shape[0]\n",
    "\n",
    "for row in test_lower.iterrows():\n",
    "    row = row[1]\n",
    "    if row['type'] == row['predicted']:\n",
    "        correct += 1\n",
    "\n",
    "print('Correct   : {}/{}'.format(correct, total))\n",
    "print('Incorrect : {}/{}'.format(total-correct, total))\n",
    "print('Accuracy  : {:.2f}%'.format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-elevation",
   "metadata": {},
   "source": [
    "### Apply the na√Øve Bayes to solve the authorship attribution problem related to the Federalist Papers (federalist-papersNew2.csv) with the twelve disputed papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "solved-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special\n",
    "import itertools\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "scientific-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= GaussianNB()\n",
    "le = preprocessing.LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "unauthorized-administrator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upon</th>\n",
       "      <th>to</th>\n",
       "      <th>would</th>\n",
       "      <th>while</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   upon  to  would  while  up\n",
       "1     6  72      2      0   0\n",
       "2     1  53      5      1   0\n",
       "3     0  56      2      0   0\n",
       "4     0  51     17      0   0\n",
       "5     0  45     37      0   0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('corpus/federalist-papersNew2.csv', index_col=0)\n",
    "words_of_interest = ['upon', 'to', 'would','while','up']\n",
    "df[words_of_interest].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "north-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed = disputed_essays = df[df['AUTHOR'] == 'Hamilton OR Madison'].index\n",
    "assert len(disputed_essays) == 12  # there are twelve disputed essays\n",
    "# numbers widely used to identify the essays\n",
    "assert set(disputed_essays) == {49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 62, 63}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "elect-highlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamilton    51\n",
      "Madison     14\n",
      "Name: AUTHOR, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>109</th>\n",
       "      <th>11</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yourselves</th>\n",
       "      <th>zaleucus</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zelden</th>\n",
       "      <th>AUTHOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows √ó 11501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    000  1  10  100  104  105  109  11  114  115  ...  young  your  yourself  \\\n",
       "1     0  2   0    0    0    0    0   0    0    0  ...      0    10         0   \n",
       "6     0  2   2    0    0    0    0   2    0    0  ...      0     0         0   \n",
       "7     0  1   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "8     0  2   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "9     0  1   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "..  ... ..  ..  ...  ...  ...  ...  ..  ...  ...  ...    ...   ...       ...   \n",
       "81    0  2   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "82    0  1   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "83    0  2   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "84    0  4   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "85    0  2   0    0    0    0    0   0    0    0  ...      0     4         0   \n",
       "\n",
       "    yourselves  zaleucus  zeal  zealand  zealous  zelden    AUTHOR  \n",
       "1            0         0     3        0        0       0  Hamilton  \n",
       "6            0         0     0        0        0       0  Hamilton  \n",
       "7            0         0     1        0        0       0  Hamilton  \n",
       "8            0         0     0        0        0       0  Hamilton  \n",
       "9            0         0     0        0        0       0  Hamilton  \n",
       "..         ...       ...   ...      ...      ...     ...       ...  \n",
       "81           0         0     0        0        0       0  Hamilton  \n",
       "82           0         0     0        0        0       0  Hamilton  \n",
       "83           0         0     0        0        0       0  Hamilton  \n",
       "84           0         0     2        0        0       0  Hamilton  \n",
       "85           0         0     1        0        2       0  Hamilton  \n",
       "\n",
       "[65 rows x 11501 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed = df_known = df.loc[df['AUTHOR'].isin(('Hamilton', 'Madison'))]\n",
    "print(df_known['AUTHOR'].value_counts())\n",
    "fed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "architectural-pattern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\veda\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5957"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_pap=fed[['upon','would','to','while','up','AUTHOR']]\n",
    "#known_pap.head()\n",
    "\n",
    "#known_pap=known_pap.groupby('AUTHOR').sum()\n",
    "#known_pap['Subset_length'] = known_pap.sum(axis=1)\n",
    "known_pap['Author_Group']=le.fit_transform(known_pap['AUTHOR'])\n",
    "known_pap=known_pap.drop('AUTHOR', axis=1)\n",
    "known_pap\n",
    "\n",
    "\n",
    "upon_prob_ham=known_pap[ known_pap['Author_Group']==0]\n",
    "upon_prob=upon_prob_ham['upon'].sum()\n",
    "print(upon_prob)\n",
    "#total_sum_ham=\n",
    "deno_ham=np.sum(upon_prob_ham.sum(),axis=0)\n",
    "deno_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "automotive-mailman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>109</th>\n",
       "      <th>11</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yourselves</th>\n",
       "      <th>zaleucus</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zelden</th>\n",
       "      <th>AUTHOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 11501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    000  1  10  100  104  105  109  11  114  115  ...  young  your  yourself  \\\n",
       "49    0  0   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "50    0  0   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "51    0  0   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "52    0  0   0    0    0    0    0   0    0    0  ...      1     0         0   \n",
       "53    0  0   0    0    0    0    0   0    0    0  ...      0     0         0   \n",
       "\n",
       "    yourselves  zaleucus  zeal  zealand  zealous  zelden               AUTHOR  \n",
       "49           0         0     0        0        0       0  Hamilton OR Madison  \n",
       "50           0         0     0        0        0       0  Hamilton OR Madison  \n",
       "51           0         0     0        0        0       0  Hamilton OR Madison  \n",
       "52           0         0     1        0        0       0  Hamilton OR Madison  \n",
       "53           0         0     1        0        0       0  Hamilton OR Madison  \n",
       "\n",
       "[5 rows x 11501 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disputed_essays = df[df['AUTHOR'] == 'Hamilton OR Madison']\n",
    "disputed_essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "healthy-murray",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upon</th>\n",
       "      <th>would</th>\n",
       "      <th>to</th>\n",
       "      <th>while</th>\n",
       "      <th>up</th>\n",
       "      <th>AUTHOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Hamilton OR Madison</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    upon  would  to  while  up               AUTHOR\n",
       "49     0     22  58      0   0  Hamilton OR Madison\n",
       "50     1     11  28      0   0  Hamilton OR Madison\n",
       "51     0      9  50      0   0  Hamilton OR Madison\n",
       "52     0      8  72      0   0  Hamilton OR Madison\n",
       "53     0      6  73      0   0  Hamilton OR Madison\n",
       "54     2      6  61      0   0  Hamilton OR Madison\n",
       "55     0     10  78      0   1  Hamilton OR Madison\n",
       "56     0      4  39      0   0  Hamilton OR Madison\n",
       "57     0      6  74      0   0  Hamilton OR Madison\n",
       "58     0     12  61      0   0  Hamilton OR Madison\n",
       "62     0      5  82      0   0  Hamilton OR Madison\n",
       "63     0     11  88      0   2  Hamilton OR Madison"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_essays=disputed_essays[['upon','would','to','while','up','AUTHOR']]\n",
    "disp_essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "nasty-tracker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upon</th>\n",
       "      <th>would</th>\n",
       "      <th>to</th>\n",
       "      <th>while</th>\n",
       "      <th>up</th>\n",
       "      <th>Author_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>51</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   upon  would  to  while  up  Author_Group\n",
       "1     6      2  72      0   0             0\n",
       "6     4      6  58      0   0             0\n",
       "7    11     51  82      0   1             0\n",
       "8     3     27  80      0   3             0\n",
       "9     4      8  71      1   0             0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_pap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "revised-carpet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "upon      0\n",
       "would    22\n",
       "to       58\n",
       "while     0\n",
       "up        0\n",
       "Name: 49, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_essay_test=disp_essays.drop('AUTHOR',axis=1)\n",
    "disputed_essays = df[df['AUTHOR'] == 'Hamilton OR Madison']\n",
    "\n",
    "print(disp_essay_test.iloc[0].loc['upon'])\n",
    "disp_essay_test.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-landscape",
   "metadata": {},
   "source": [
    "#### Naive Bayes Model with different attributes:\n",
    "\n",
    "1. Calculate prior for all catergories of the Output\n",
    "2. Calculate the conditional probability for each category for each attribute\n",
    "3. Sumthe log of conditional probability and prior for each catergory\n",
    "4. Obtain the argmax for the \n",
    "5. Repeat steps for each test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "champion-buyer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7846153846153846, 0.2153846153846154]\n",
      "value x=   0\n",
      "0 features := upon 0 0\n",
      "prob=  0.06289835625628984\n",
      "0.0 features := would 0 22\n",
      "prob=  0.1559879235155988\n",
      "-40.875487137995734 features := to 0 58\n",
      "prob=  0.7690372358269038\n",
      "-56.10720873174792 features := while 0 0\n",
      "prob=  0.006205971150620597\n",
      "-56.10720873174792 features := up 0 0\n",
      "prob=  0.005870513250587051\n",
      "posteriors [-56.34977036891923]\n",
      "0 features := upon 0 0\n",
      "prob=  0.005521048999309869\n",
      "0.0 features := would 0 22\n",
      "prob=  0.11042097998619738\n",
      "-48.476012795910826 features := to 0 58\n",
      "prob=  0.8709454796411318\n",
      "-56.490214950643214 features := while 0 0\n",
      "prob=  0.0006901311249137336\n",
      "-56.490214950643214 features := up 0 0\n",
      "prob=  0.0027605244996549345\n",
      "posteriors [-56.34977036891923, -58.02554489092359]\n",
      "value x=   1\n",
      "0 features := upon 1 1\n",
      "prob=  0.06289835625628984\n",
      "-2.766235248267606 features := would 1 11\n",
      "prob=  0.1559879235155988\n",
      "-23.203978817265472 features := to 1 28\n",
      "prob=  0.7690372358269038\n",
      "-30.557223724594113 features := while 1 0\n",
      "prob=  0.006205971150620597\n",
      "-30.557223724594113 features := up 1 0\n",
      "prob=  0.005870513250587051\n",
      "posteriors [-30.799785361765423]\n",
      "0 features := upon 1 1\n",
      "prob=  0.005521048999309869\n",
      "-5.199187400640846 features := would 1 11\n",
      "prob=  0.11042097998619738\n",
      "-29.437193798596258 features := to 1 28\n",
      "prob=  0.8709454796411318\n",
      "-33.30611897674293 features := while 1 0\n",
      "prob=  0.0006901311249137336\n",
      "-33.30611897674293 features := up 1 0\n",
      "prob=  0.0027605244996549345\n",
      "posteriors [-30.799785361765423, -34.84144891702331]\n",
      "value x=   2\n",
      "0 features := upon 2 0\n",
      "prob=  0.06289835625628984\n",
      "0.0 features := would 2 9\n",
      "prob=  0.1559879235155988\n",
      "-16.721790192816435 features := to 2 50\n",
      "prob=  0.7690372358269038\n",
      "-29.85258467018901 features := while 2 0\n",
      "prob=  0.006205971150620597\n",
      "-29.85258467018901 features := up 2 0\n",
      "prob=  0.005870513250587051\n",
      "posteriors [-30.09514630736032]\n",
      "0 features := upon 2 0\n",
      "prob=  0.005521048999309869\n",
      "0.0 features := would 2 9\n",
      "prob=  0.11042097998619738\n",
      "-19.8310961437817 features := to 2 50\n",
      "prob=  0.8709454796411318\n",
      "-26.7398911047579 features := while 2 0\n",
      "prob=  0.0006901311249137336\n",
      "-26.7398911047579 features := up 2 0\n",
      "prob=  0.0027605244996549345\n",
      "posteriors [-30.09514630736032, -28.275221045038275]\n",
      "value x=   3\n",
      "0 features := upon 3 0\n",
      "prob=  0.06289835625628984\n",
      "0.0 features := would 3 8\n",
      "prob=  0.1559879235155988\n",
      "-14.863813504725721 features := to 3 72\n",
      "prob=  0.7690372358269038\n",
      "-33.772157552142225 features := while 3 0\n",
      "prob=  0.006205971150620597\n",
      "-33.772157552142225 features := up 3 0\n",
      "prob=  0.005870513250587051\n",
      "posteriors [-34.01471918931354]\n",
      "0 features := upon 3 0\n",
      "prob=  0.005521048999309869\n",
      "0.0 features := would 3 8\n",
      "prob=  0.11042097998619738\n",
      "-17.627641016694845 features := to 3 72\n",
      "prob=  0.8709454796411318\n",
      "-27.576305760500567 features := while 3 0\n",
      "prob=  0.0006901311249137336\n",
      "-27.576305760500567 features := up 3 0\n",
      "prob=  0.0027605244996549345\n",
      "posteriors [-34.01471918931354, -29.111635700780944]\n",
      "value x=   4\n",
      "0 features := upon 4 0\n",
      "prob=  0.06289835625628984\n",
      "0.0 features := would 4 6\n",
      "prob=  0.1559879235155988\n",
      "-11.147860128544291 features := to 4 73\n",
      "prob=  0.7690372358269038\n",
      "-30.31882006550825 features := while 4 0\n",
      "prob=  0.006205971150620597\n",
      "-30.31882006550825 features := up 4 0\n",
      "prob=  0.005870513250587051\n",
      "posteriors [-30.561381702679558]\n",
      "0 features := upon 4 0\n",
      "prob=  0.005521048999309869\n",
      "0.0 features := would 4 6\n",
      "prob=  0.11042097998619738\n",
      "-13.220730762521134 features := to 4 73\n",
      "prob=  0.8709454796411318\n",
      "-23.307571405546383 features := while 4 0\n",
      "prob=  0.0006901311249137336\n",
      "-23.307571405546383 features := up 4 0\n",
      "prob=  0.0027605244996549345\n",
      "posteriors [-30.561381702679558, -24.84290134582676]\n",
      "value x=   5\n",
      "0 features := upon 5 2\n",
      "prob=  0.06289835625628984\n",
      "-5.532470496535212 features := would 5 6\n",
      "prob=  0.1559879235155988\n",
      "-16.680330625079502 features := to 5 61\n",
      "prob=  0.7690372358269038\n",
      "-32.69989988747405 features := while 5 0\n",
      "prob=  0.006205971150620597\n",
      "-32.69989988747405 features := up 5 0\n",
      "prob=  0.005870513250587051\n",
      "posteriors [-32.94246152464536]\n",
      "0 features := upon 5 2\n",
      "prob=  0.005521048999309869\n",
      "-10.398374801281692 features := would 5 6\n",
      "prob=  0.11042097998619738\n",
      "-23.619105563802826 features := to 5 61\n",
      "prob=  0.8709454796411318\n",
      "-32.047835416193784 features := while 5 0\n",
      "prob=  0.0006901311249137336\n",
      "-32.047835416193784 features := up 5 0\n",
      "prob=  0.0027605244996549345\n",
      "posteriors [-32.94246152464536, -33.58316535647416]\n",
      "value x=   6\n",
      "0 features := upon 6 0\n",
      "prob=  0.06289835625628984\n",
      "0.0 features := would 6 10\n",
      "prob=  0.1559879235155988\n",
      "-18.57976688090715 features := to 6 78\n",
      "prob=  0.7690372358269038\n",
      "-39.06380626560836 features := while 6 0\n",
      "prob=  0.006205971150620597\n",
      "-39.06380626560836 features := up 6 1\n",
      "prob=  0.005870513250587051\n",
      "posteriors [-44.44418111552828]\n",
      "0 features := upon 6 0\n",
      "prob=  0.005521048999309869\n",
      "0.0 features := would 6 10\n",
      "prob=  0.11042097998619738\n",
      "-22.034551270868555 features := to 6 78\n",
      "prob=  0.8709454796411318\n",
      "-32.812271409991425 features := while 6 0\n",
      "prob=  0.0006901311249137336\n",
      "-32.812271409991425 features := up 6 1\n",
      "prob=  0.0027605244996549345\n",
      "posteriors [-44.44418111552828, -40.239935931472594]\n",
      "value x=   7\n",
      "0 features := upon 7 0\n",
      "prob=  0.06289835625628984\n",
      "0.0 features := would 7 4\n",
      "prob=  0.1559879235155988\n",
      "-7.431906752362861 features := to 7 39\n",
      "prob=  0.7690372358269038\n",
      "-17.67392644471347 features := while 7 0\n",
      "prob=  0.006205971150620597\n",
      "-17.67392644471347 features := up 7 0\n",
      "prob=  0.005870513250587051\n",
      "posteriors [-17.91648808188478]\n",
      "0 features := upon 7 0\n",
      "prob=  0.005521048999309869\n",
      "0.0 features := would 7 4\n",
      "prob=  0.11042097998619738\n",
      "-8.813820508347423 features := to 7 39\n",
      "prob=  0.8709454796411318\n",
      "-14.202680577908858 features := while 7 0\n",
      "prob=  0.0006901311249137336\n",
      "-14.202680577908858 features := up 7 0\n",
      "prob=  0.0027605244996549345\n",
      "posteriors [-17.91648808188478, -15.738010518189236]\n",
      "value x=   8\n",
      "0 features := upon 8 0\n",
      "prob=  0.06289835625628984\n",
      "0.0 features := would 8 6\n",
      "prob=  0.1559879235155988\n",
      "-11.147860128544291 features := to 8 74\n",
      "prob=  0.7690372358269038\n",
      "-30.5814359550557 features := while 8 0\n",
      "prob=  0.006205971150620597\n",
      "-30.5814359550557 features := up 8 0\n",
      "prob=  0.005870513250587051\n",
      "posteriors [-30.82399759222701]\n",
      "0 features := upon 8 0\n",
      "prob=  0.005521048999309869\n",
      "0.0 features := would 8 6\n",
      "prob=  0.11042097998619738\n",
      "-13.220730762521134 features := to 8 74\n",
      "prob=  0.8709454796411318\n",
      "-23.445747304765906 features := while 8 0\n",
      "prob=  0.0006901311249137336\n",
      "-23.445747304765906 features := up 8 0\n",
      "prob=  0.0027605244996549345\n",
      "posteriors [-30.82399759222701, -24.981077245046283]\n",
      "value x=   9\n",
      "0 features := upon 9 0\n",
      "prob=  0.06289835625628984\n",
      "0.0 features := would 9 12\n",
      "prob=  0.1559879235155988\n",
      "-22.295720257088583 features := to 9 61\n",
      "prob=  0.7690372358269038\n",
      "-38.31528951948312 features := while 9 0\n",
      "prob=  0.006205971150620597\n",
      "-38.31528951948312 features := up 9 0\n",
      "prob=  0.005870513250587051\n",
      "posteriors [-38.557851156654436]\n",
      "0 features := upon 9 0\n",
      "prob=  0.005521048999309869\n",
      "0.0 features := would 9 12\n",
      "prob=  0.11042097998619738\n",
      "-26.441461525042268 features := to 9 61\n",
      "prob=  0.8709454796411318\n",
      "-34.87019137743323 features := while 9 0\n",
      "prob=  0.0006901311249137336\n",
      "-34.87019137743323 features := up 9 0\n",
      "prob=  0.0027605244996549345\n",
      "posteriors [-38.557851156654436, -36.40552131771361]\n",
      "value x=   10\n",
      "0 features := upon 10 0\n",
      "prob=  0.06289835625628984\n",
      "0.0 features := would 10 5\n",
      "prob=  0.1559879235155988\n",
      "-9.289883440453576 features := to 10 82\n",
      "prob=  0.7690372358269038\n",
      "-30.824386383344596 features := while 10 0\n",
      "prob=  0.006205971150620597\n",
      "-30.824386383344596 features := up 10 0\n",
      "prob=  0.005870513250587051\n",
      "posteriors [-31.066948020515905]\n",
      "0 features := upon 10 0\n",
      "prob=  0.005521048999309869\n",
      "0.0 features := would 10 5\n",
      "prob=  0.11042097998619738\n",
      "-11.017275635434277 features := to 10 82\n",
      "prob=  0.8709454796411318\n",
      "-22.34769937143524 features := while 10 0\n",
      "prob=  0.0006901311249137336\n",
      "-22.34769937143524 features := up 10 0\n",
      "prob=  0.0027605244996549345\n",
      "posteriors [-31.066948020515905, -23.883029311715617]\n",
      "value x=   11\n",
      "0 features := upon 11 0\n",
      "prob=  0.06289835625628984\n",
      "0.0 features := would 11 11\n",
      "prob=  0.1559879235155988\n",
      "-20.437743568997867 features := to 11 88\n",
      "prob=  0.7690372358269038\n",
      "-43.5479418491736 features := while 11 0\n",
      "prob=  0.006205971150620597\n",
      "-43.5479418491736 features := up 11 2\n",
      "prob=  0.005870513250587051\n",
      "posteriors [-54.06612991184212]\n",
      "0 features := upon 11 0\n",
      "prob=  0.005521048999309869\n",
      "0.0 features := would 11 11\n",
      "prob=  0.11042097998619738\n",
      "-24.238006397955413 features := to 11 88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob=  0.8709454796411318\n",
      "-36.397485529273524 features := while 11 0\n",
      "prob=  0.0006901311249137336\n",
      "-36.397485529273524 features := up 11 2\n",
      "prob=  0.0027605244996549345\n",
      "posteriors [-54.06612991184212, -49.717484631955486]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prior(df,Y):\n",
    "    classes= df[Y].unique()\n",
    "    prior=[]\n",
    "    for category in classes:\n",
    "        prior.append(len(df[df[Y]==category])/len(df))\n",
    "        #print(prior)\n",
    "    return prior\n",
    "def conditional_probability(df,feat_name,feat_val,Y,label):\n",
    "    feat=list(df.columns)\n",
    "    df=df[df[Y]==label]\n",
    "    alpha=1\n",
    "    num= df[feat_name].sum()+1\n",
    "    dem=np.sum(df.sum(),axis=0)+feat_val\n",
    "    print('prob= ',num/dem)\n",
    "    return np.log(num/dem)\n",
    "\n",
    "def naive_bayes(df,X_test,Category):\n",
    "    features= list(df.columns)[:-1]\n",
    "    classes=df[Category].unique()\n",
    "    priors=[]\n",
    "    priors=prior(df,Category)\n",
    "    print(priors)\n",
    "    Y_pred=[]\n",
    "    \n",
    "    for x in range(len(X_test)):\n",
    "        print('value x=  ',x)\n",
    "       \n",
    "        classes=list(df[Category].unique())\n",
    "        posteriors=[]\n",
    "        \n",
    "        for i in range((len(classes))):\n",
    "            posterior=0\n",
    "            \n",
    "            cond_prob=0\n",
    "            for j in range(len(features)):\n",
    "                count=X_test.iloc[x].loc[features[j]]\n",
    "                print(cond_prob,'features :=',features[j], x,count)\n",
    "                cond_prob+=count*conditional_probability(df,features[j],len(features),Category,classes[i])\n",
    "            posterior=np.log(priors[i])+cond_prob\n",
    "            posteriors.append(posterior)\n",
    "            print('posteriors',posteriors)\n",
    "        Y_pred.append(np.argmax(posteriors))\n",
    "    return np.array(Y_pred)\n",
    "\n",
    "\n",
    "df=known_pap    \n",
    "X_test=disp_essay_test\n",
    "naive_bayes(df,X_test,Category='Author_Group')\n",
    "#X_train=known_pap[['upon','would','to','while','up']]\n",
    "#Y_train=known_pap['Author_Group']\n",
    "#fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "incomplete-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train=known_pap[['upon','would','to','while','up']]\n",
    "# Y_train=known_pap['Author_Group']\n",
    "# X_test=disp_essay_\n",
    "# clf.fit(X_train,Y_train)\n",
    "# y_pred=clf.predict(X_test)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "better-madness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: Author_Group, dtype: int32"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train=known_pap['Author_Group']\n",
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "catholic-atlas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "soviet-tackle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 1     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "     ..\n",
       "81    0\n",
       "82    0\n",
       "83    0\n",
       "84    0\n",
       "85    0\n",
       "Name: Author_Group, Length: 65, dtype: int32>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "worth-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X,Y):\n",
    "    n_sample,n_feature=X.shape\n",
    "    classes= np.unique(Y)\n",
    "    n_classes=len(classes)\n",
    "    #for c in np.unique(Y):\n",
    "    mean_all=np.zeros((n_classes,n_feature),dtype=np.float64)    \n",
    "    var_all=np.zeros((n_classes,n_feature),dtype=np.float64)    \n",
    "    priors_all=np.zeros(n_classes,dtype=np.float64)\n",
    "    \n",
    "    for c in classes:\n",
    "        X_c=X[c==Y]\n",
    "        mean_all[c,:]=X_c.mean(axis=0)\n",
    "        var_all[c,:]=X_c.var(axis=0)\n",
    "        priors_all[c]=X_C.shape[0]/float(n_sample)\n",
    "   # return var_all[1,]\n",
    "def predit(X_test):\n",
    "    y_pred=np.zeros(len(X_test),dtype=np.float64)\n",
    "    for x in X_test:\n",
    "        posteriors=[]\n",
    "        \n",
    "        for index,col in enumerate(classes):\n",
    "                prior=np.log(priors_all[index])\n",
    "                class_conditional= np.sum(np.log(pdf(index,x)))\n",
    "                posterior=prior+class_conditional\n",
    "                posteriors.append(posterior)\n",
    "        y_pred.append(np.argmax(posteriors))\n",
    "    return y_pred\n",
    "\n",
    "def pdf(index,x):\n",
    "    mean= mean_all[index]\n",
    "    var=var_all[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-weekly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
