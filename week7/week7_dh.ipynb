{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "secure-curtis",
   "metadata": {},
   "source": [
    "# Week 7 : Digital humanities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-revelation",
   "metadata": {},
   "source": [
    "### Q2. Give one problem when applying the direct estimation as suggested by Mary. Provide two drawbacks related to Laplace smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-membrane",
   "metadata": {},
   "source": [
    "Problem ocuure if any word not present in the word tokens then related probability will zero for corresponding word\n",
    "\n",
    "#### Drawbacks of laplace smoothing:\n",
    "- If word type id infinite then too much probability mass is shifted towards unseen n-grams\n",
    "- Probability of rare (or unseen) n-grams is overestimated\n",
    "- All unseen n-grams are smoothed in the same way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-singer",
   "metadata": {},
   "source": [
    "### Q3. Generate the bigrams of tokens. Provide the ten most frequent bigrams from tweets written by a woman or a man."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "differential-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "functioning-republic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alex is too nice for love island :(   0\n"
     ]
    }
   ],
   "source": [
    "aListOfTweets = []\n",
    "myInputFile = open('./corpus/tweets.female.txt', 'r', encoding=\"utf8\")\n",
    "aLine = myInputFile.readline()\n",
    "IDs=[]\n",
    "while aLine:\n",
    "    myLine = aLine.split('\\t')\n",
    "    IDs.append(myLine[0])\n",
    "    \n",
    "    aFinalLine = ''\n",
    "    for aSubLine in myLine[3:]:\n",
    "        aSubLine = re.sub('\\n', '', aSubLine)\n",
    "        aFinalLine += aSubLine + ' '\n",
    "    aListOfTweets.append(aFinalLine)\n",
    "    aLine = myInputFile.readline()\n",
    "\n",
    "print(aListOfTweets[0], IDs[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "several-touch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 bigram tweets and their counts by female are: \n",
      "('rt', '@') 39059\n",
      "(\"'\", 's') 10165\n",
      "('â€™', 's') 6098\n",
      "(\"'\", 't') 5077\n",
      "('i', \"'\") 4834\n",
      "('.', 'urllink') 4350\n",
      "('in', 'the') 4206\n",
      "('â€™', 't') 3644\n",
      "('of', 'the') 3620\n",
      "('â€¦', 'urllink') 3122\n",
      "('urllink', 'â€¦') 3112\n",
      "(':', 'urllink') 3029\n",
      "(\"'\", 'm') 2931\n",
      "('it', \"'\") 2807\n",
      "('i', 'â€™') 2775\n",
      "('urllink', 'urllink') 2594\n",
      "('.', 'i') 2460\n",
      "('on', 'the') 2340\n",
      "('.', '#') 2302\n",
      "('to', 'be') 2239\n"
     ]
    }
   ],
   "source": [
    "b_gram = []\n",
    "for total_words in aListOfTweets:\n",
    "    b_gram.extend(list(nltk.bigrams(total_words.split())))\n",
    "\n",
    "\n",
    "frequency = nltk.FreqDist(b_gram)\n",
    "dict_sorted = {k: v for k, v in sorted(frequency.items(), key=lambda item: item[1], reverse=True)}\n",
    "bgram_10_words_f = list(dict_sorted.keys())[:20]\n",
    "\n",
    "print(\"Top 20 bigram tweets and their counts by female are: \")\n",
    "for key in bgram_10_words_f:\n",
    "    print(key,dict_sorted[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "warming-swedish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ jennycastle 96 ahaha last time acting reckless ðŸ˜‚ðŸ˜‚   6\n"
     ]
    }
   ],
   "source": [
    "aListOfTweets_male = []\n",
    "myInputFile_male = open('./corpus/tweets.male.txt', 'r', encoding=\"utf8\")\n",
    "aLine = myInputFile_male.readline()\n",
    "IDs_male=[]\n",
    "while aLine:\n",
    "    myLine = aLine.split('\\t')\n",
    "    IDs_male.append(myLine[0])\n",
    "    \n",
    "    aFinalLine = ''\n",
    "    for aSubLine in myLine[3:]:\n",
    "        aSubLine = re.sub('\\n', '', aSubLine)\n",
    "        aFinalLine += aSubLine + ' '\n",
    "    aListOfTweets_male.append(aFinalLine)\n",
    "    aLine = myInputFile_male.readline()\n",
    "\n",
    "print(aListOfTweets_male[0], IDs_male[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "related-cancellation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 bigram tweets and their counts by male are: \n",
      "('rt', '@') 30619\n",
      "(\"'\", 's') 12366\n",
      "('.', 'urllink') 6800\n",
      "(\"'\", 't') 6759\n",
      "('â€™', 's') 4948\n",
      "('in', 'the') 4514\n",
      "('i', \"'\") 4382\n",
      "('of', 'the') 4206\n",
      "('it', \"'\") 3596\n",
      "('.', '#') 3050\n",
      "('on', 'the') 2718\n",
      "('urllink', 'â€¦') 2585\n",
      "('â€™', 't') 2567\n",
      "('.', 'i') 2510\n",
      "('for', 'the') 2435\n",
      "(\"'\", 'm') 2401\n",
      "('don', \"'\") 2209\n",
      "('this', 'is') 2182\n",
      "(':', 'urllink') 2115\n",
      "('to', 'be') 2112\n"
     ]
    }
   ],
   "source": [
    "b_gram = []\n",
    "for total_words in aListOfTweets_male:\n",
    "    b_gram.extend(list(nltk.bigrams(total_words.split())))\n",
    "\n",
    "\n",
    "frequency = nltk.FreqDist(b_gram)\n",
    "dict_sorted = {k: v for k, v in sorted(frequency.items(), key=lambda item: item[1], reverse=True)}\n",
    "bgram_10_words_m = list(dict_sorted.keys())[:20]\n",
    "\n",
    "print(\"Top 20 bigram tweets and their counts by male are: \")\n",
    "for key in bgram_10_words_m:\n",
    "    print(key, dict_sorted[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-apple",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Discussion\n",
    "\n",
    "#### In both  male and female bigrams, the common tweets such ('rt', '@'), (\"'\", 's'), (\".\", 'urllink') etc.  have been observed since it is mandated by the Twitter to follow that template. As far as I can see the top tweets are discriminative enough to classify the gender from them\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
