{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "understood-district",
   "metadata": {},
   "source": [
    "### Week7: Digital Humanities - Vector Space Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pleasant-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lxml.etree\n",
    "import tarfile\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import nltk.tokenize\n",
    "import math\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "union-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf = tarfile.open('theatre-classique.tar.gz','r')\n",
    "# tf.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bearing-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgenres = ('Comédie', 'Tragédie', 'Tragi-comédie')\n",
    "#print(subgenres)\n",
    "plays, titles, genres = [], [], []\n",
    "authors, years = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "colored-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in os.scandir('data/theatre-classique'):\n",
    "    # Only include XML files\n",
    "    if not fn.name.endswith('.xml'):\n",
    "        continue\n",
    "    tree   = lxml.etree.parse(fn.path)\n",
    "    genre  = tree.find('//genre')\n",
    "    title  = tree.find('//title')\n",
    "    author = tree.find('//author')\n",
    "    year   = tree.find('//date')\n",
    "    if genre is not None and genre.text in subgenres:\n",
    "        lines = []\n",
    "        for line in tree.xpath('//l|//p'):\n",
    "            lines.append(' '.join(line.itertext()))\n",
    "        text = '\\n'.join(lines)\n",
    "        plays.append(text)\n",
    "        genres.append(genre.text)\n",
    "        titles.append(title.text)\n",
    "        authors.append(author.text)\n",
    "        if year is not None:\n",
    "            years.append(year.text)\n",
    "\n",
    "plays = np.array(plays)\n",
    "genres = np.array(genres)\n",
    "titles = np.array(titles)\n",
    "authors = np.array(authors)\n",
    "years = np.array(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intensive-regulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498 498 498 498 208\n"
     ]
    }
   ],
   "source": [
    "print(len(plays), len(genres), len(titles), len(authors), len(years))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "occupied-cloud",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Veda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sacred-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_punct(string):\n",
    "    \"\"\"Check if STRING is a punctuation marker or a sequence of\n",
    "       punctuation markers.\n",
    "    \"\"\"\n",
    "    return PUNCT_RE.match(string) is not None\n",
    "\n",
    "PUNCT_RE = re.compile(r'[^\\w\\s]+$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "premier-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, language='French', lowercase=True):\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    if (language == 'French'):\n",
    "        text = re.sub(\"-\", \" \", text)\n",
    "        text = re.sub(\"l'\", \"le \", text)\n",
    "        text = re.sub(\"d'\", \"de \", text)\n",
    "        text = re.sub(\"c'\", \"ce \", text)\n",
    "        text = re.sub(\"j'\", \"je \", text)\n",
    "        text = re.sub(\"m'\", \"me \", text)\n",
    "        text = re.sub(\"qu'\", \"que \", text)\n",
    "        text = re.sub(\"'\", \" ' \", text)\n",
    "        text = re.sub(\"quelqu'\", \"quelque \", text)\n",
    "        text = re.sub(\"aujourd'hui\", \"aujourdhui\", text)\n",
    "    tokens = nltk.tokenize.word_tokenize(text, language=language)\n",
    "    tokens = [token for token in tokens if not is_punct(token)]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surface-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "plays_tok = [preprocess_text(play, 'French') for play in plays]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "great-sarah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary:  62967\n"
     ]
    }
   ],
   "source": [
    "def extract_vocabulary(tokenized_corpus, min_count=1, max_count=float('inf')):\n",
    "    vocabulary = collections.Counter()\n",
    "    for document in tokenized_corpus:\n",
    "        vocabulary.update(document)\n",
    "    vocabulary = {word for word, count in vocabulary.items()\n",
    "                  if count >= min_count and count <= max_count}\n",
    "    return sorted(vocabulary)\n",
    "\n",
    "vocabulary = extract_vocabulary(plays_tok)  # , min_count=2\n",
    "print(\"Length of vocabulary: \",len(vocabulary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "social-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus2dtm(tokenized_corpus, vocabulary):\n",
    "    document_term_matrix = []\n",
    "    for document in tokenized_corpus:\n",
    "        document_counts = collections.Counter(document)\n",
    "        row = [document_counts[word] for word in vocabulary]\n",
    "        document_term_matrix.append(row)\n",
    "    return np.array(document_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "specific-andrews",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document-term matrix with |D| = 498 documents and |V| = 62967 words.\n"
     ]
    }
   ],
   "source": [
    "document_term_matrix = np.array(corpus2dtm(plays_tok, vocabulary))\n",
    "print(f\"document-term matrix with \"\n",
    "      f\"|D| = {document_term_matrix.shape[0]} documents and \"\n",
    "      f\"|V| = {document_term_matrix.shape[1]} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "brutal-looking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted doc into vectors :\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "Length of matrix: \n",
      " 498\n",
      "\n",
      "Size of matrix: \n",
      " (498, 62967)\n"
     ]
    }
   ],
   "source": [
    "print(\"Converted doc into vectors :\\n\",document_term_matrix)\n",
    "print(\"\\nLength of matrix: \\n\", len(document_term_matrix))\n",
    "print(\"\\nSize of matrix: \\n\", document_term_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-atlas",
   "metadata": {},
   "source": [
    "### Q1. For each genre, generate a “profile” in the form of a single vector representing the entire set of plays corresponding to this genre. Build such a profile for each of the three genres (Comedy, Tragedy and Tragicomedy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "flying-boulder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62967,) (62967,) (62967,)\n"
     ]
    }
   ],
   "source": [
    "tr_means = document_term_matrix[np.array(genres) == 'Tragédie'].mean(axis=0)\n",
    "co_means = document_term_matrix[genres == 'Comédie'].mean(axis=0)\n",
    "tc_means = document_term_matrix[genres == 'Tragi-comédie'].mean(axis=0)\n",
    "\n",
    "print(tr_means.shape, co_means.shape, tc_means.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-harvard",
   "metadata": {},
   "source": [
    "### Q2. Which are the three plays for each text genre (or group) that are the “closest” to the profile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "descending-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_len(v):\n",
    "    \"\"\"Compute the length (or norm) of a vector.\"\"\"\n",
    "    return (np.sqrt(np.sum(v ** 2)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "geological-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine distance\n",
    "def cosine_distance(a, b):\n",
    "    return ( 1 - np.dot(a, b) / (vector_len(a) * vector_len(b)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "lined-signal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tragédies - comédies:       0.03\n",
      "tragédies - tragi-comédies: 0.01\n",
      " comédies - tragi-comédies: 0.02\n"
     ]
    }
   ],
   "source": [
    "tragedy_comedy = cosine_distance(tr_means, co_means)\n",
    "tragedy_tragedyComedy = cosine_distance(tr_means, tc_means)\n",
    "tragedyComedy_comedy = cosine_distance(co_means, tc_means)\n",
    "print(f'tragédies - comédies:       {tragedy_comedy:.2f}')\n",
    "print(f'tragédies - tragi-comédies: {tragedy_tragedyComedy:.2f}')\n",
    "print(f' comédies - tragi-comédies: {tragedyComedy_comedy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-romania",
   "metadata": {},
   "source": [
    "#### Finding the distance between the profile and each play in the given category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "similar-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dists, c_dists, tc_dists = [], [], []\n",
    "\n",
    "for aPlay in document_term_matrix[genres == 'Comédie']:\n",
    "    c_dists.append(cosine_distance(aPlay, co_means))\n",
    "\n",
    "for aPlay in document_term_matrix[genres == 'Tragédie']:\n",
    "    t_dists.append(cosine_distance(aPlay, tr_means))\n",
    "\n",
    "for aPlay in document_term_matrix[genres == 'Tragi-comédie']:\n",
    "    tc_dists.append(cosine_distance(aPlay, tc_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "periodic-pillow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean distance to comédie vector:0.040, and Standard deviation:0.0206\n",
      "Mean distance to Tragédie vector:0.030, and Standard deviation:0.0144\n",
      "Mean distance to Tragi-comédie vector:0.024,and Standard deviation:0.0092\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean distance to comédie vector:{:.3f}, and Standard deviation:{:.4f}\".format(np.mean(c_dists),np.std(c_dists)))\n",
    "print(\"Mean distance to Tragédie vector:{:.3f}, and Standard deviation:{:.4f}\".format(np.mean(t_dists),np.std(t_dists)))\n",
    "print(\"Mean distance to Tragi-comédie vector:{:.3f},and Standard deviation:{:.4f}\".format(np.mean(tc_dists),np.std(tc_dists)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-stream",
   "metadata": {},
   "source": [
    "\n",
    "#### From these arrays, we can sort the distances to find the plays closed to the category vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "minus-saturday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'ÉCOLE DES FEMMES, COMÉDIE.\n",
      "LES MÉNECHMES, ou LES JUMEAUX, COMÉDIE\n",
      "LA COMÉDIE SANS TITRE, COMÉDIE.\n"
     ]
    }
   ],
   "source": [
    "# top 3 titles of genre comédie which are close to category vector\n",
    "\n",
    "c_dists = np.array(c_dists)\n",
    "top_three_c = c_dists.argsort()[:3]\n",
    "c_titles = np.array(titles)[genres == 'Comédie']\n",
    "print('\\n'.join(c_titles[top_three_c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "worse-participation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRÈNE, TRAGÉDIE\n",
      "MARIAMNE, TRAGÉDIE EN CINQ ACTES.\n",
      "GUSTAVE WASA, TRAGÉDIE\n"
     ]
    }
   ],
   "source": [
    "# top 3 titles of genre Tragédie which are close to category vector\n",
    "\n",
    "t_dists = np.array(t_dists)\n",
    "top_three_t = t_dists.argsort()[:3]\n",
    "t_titles = np.array(titles)[genres == 'Tragédie']\n",
    "print('\\n'.join(t_titles[top_three_t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "outstanding-indian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EURIMÉDON OU L'ILLUSTRE PIRATE. TRAGI-COMÉDIE.\n",
      "LA BRADAMANTE, TRAGI-COMÉDIE.\n",
      "LE PRINCE DÉGUISÉ, TRAGI-COMÉDIE\n"
     ]
    }
   ],
   "source": [
    "# top 3 titles of genre Tragi-comédie which are close to category vector\n",
    "\n",
    "tc_dists = np.array(tc_dists)\n",
    "top_three_tc = tc_dists.argsort()[:3]\n",
    "tc_titles = np.array(titles)[genres == 'Tragi-comédie']\n",
    "print('\\n'.join(tc_titles[top_three_tc]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-harvest",
   "metadata": {},
   "source": [
    "### Q3. Usually, we generate a profile by averaging over all term frequencies of plays belonging to a certain group. Do you know another way to generate a profile from a set of documents (or vectors)? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-draft",
   "metadata": {},
   "source": [
    "Insteate of generating a profile by averaging over all term frequencies of plays belonging to a certain group, we can generate a profile by using the play which is most typical to the category and we can observed the similar plays.\n",
    "\n",
    "For ex: Tragedy genre I obtainbelow plays which are almost same as while considering all term frequencies\n",
    "1. IRÈNE, TRAGÉDIE\n",
    "2. MARIAMNE, TRAGÉDIE EN CINQ ACTES.\n",
    "3. SOPHONISBE , TRAGÉDIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "requested-running",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 62967)\n",
      "(1, 62967)\n",
      "310\n"
     ]
    }
   ],
   "source": [
    "top_comedy = np.where(titles == \"L'ÉCOLE DES FEMMES, COMÉDIE.\")[0]\n",
    "comedy_play = document_term_matrix[top_comedy]\n",
    "print(comedy_play.shape)\n",
    "\n",
    "top_tragedy = np.where(titles == \"IRÈNE, TRAGÉDIE\")[0]\n",
    "tragedy_play = document_term_matrix[top_tragedy]\n",
    "print(tragedy_play.shape)\n",
    "\n",
    "top_tragedy_comedy = np.where(titles == \"EURIMÉDON OU L'ILLUSTRE PIRATE. TRAGI-COMÉDIE.\")[0]\n",
    "tragedy_comedy_play = document_term_matrix[top_tragedy_comedy]\n",
    "\n",
    "t_dists_new, c_dists_new, tc_dists_new = [], [], []\n",
    "\n",
    "for aPlay in document_term_matrix[genres == 'Comédie']:\n",
    "    c_dists_new.append(cosine_distance(comedy_play, aPlay))\n",
    "    #print(aPlay.shape,comedy_play.shape)\n",
    "\n",
    "print(len(c_dists_new))\n",
    "    \n",
    "#c_play_transport = np.transpose(comedy_play_transport)\n",
    "for aPlay in document_term_matrix[genres == 'Tragédie']:\n",
    "    t_dists_new.append(cosine_distance(tragedy_play, aPlay))\n",
    "\n",
    "for aPlay in document_term_matrix[genres == 'Tragi-comédie']:\n",
    "    tc_dists_new.append(cosine_distance(tragedy_comedy_play, aPlay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "photographic-deviation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192 193 202] 0.0514521395612508\n",
      "(310,)\n",
      "L'ÉCOLE DES FEMMES, COMÉDIE.\n",
      "L'ÉCOLE DES MARIS, COMÉDIE\n",
      "LE MISANTHROPE ou L'ATRABILAIRE AMOUREUX, COMÉDIE\n"
     ]
    }
   ],
   "source": [
    "c_dists_new = np.array(c_dists_new).squeeze()\n",
    "top_three_c_new = c_dists_new.argsort()[:3]\n",
    "print(top_three_c_new, c_dists_new.mean())\n",
    "c_titles_new = np.array(titles)\n",
    "c_titles_new = c_titles_new[genres == 'Comédie']\n",
    "print(c_dists_new.shape)\n",
    "\n",
    "top_three_comedy_titles  = c_titles_new[top_three_c_new]\n",
    "print('\\n'.join([str(v) for v in top_three_comedy_titles]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "suspected-optimum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138 107 117] 0.04151532612412573\n",
      "IRÈNE, TRAGÉDIE\n",
      "MARIAMNE, TRAGÉDIE EN CINQ ACTES.\n",
      "SOPHONISBE , TRAGÉDIE\n"
     ]
    }
   ],
   "source": [
    "t_dists_new = np.array(t_dists_new).squeeze()\n",
    "top_three_t_new = t_dists_new.argsort()[:3]\n",
    "print(top_three_t_new, t_dists_new.mean())\n",
    "\n",
    "t_titles_new = np.array(titles)\n",
    "t_titles_new = t_titles_new[genres == 'Tragédie']\n",
    "#print(t_dists_new.shape)\n",
    "\n",
    "top_three_tcomedy_titles  = t_titles_new[top_three_t_new]\n",
    "print('\\n'.join([str(v) for v in top_three_tcomedy_titles]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "excess-cache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 22 23] 0.03633557480762004\n",
      "(38,)\n",
      "EURIMÉDON OU L'ILLUSTRE PIRATE. TRAGI-COMÉDIE.\n",
      "AGESILAN de COLCHOS, TRAGI-COMÉDIE\n",
      "AMÉLIE, TRAGI-COMÉDIE\n"
     ]
    }
   ],
   "source": [
    "tc_dists_new = np.array(tc_dists_new).squeeze()\n",
    "top_three_tc_new = tc_dists_new.argsort()[:3]\n",
    "print(top_three_tc_new, tc_dists_new.mean())\n",
    "tc_titles_new = np.array(titles)\n",
    "tc_titles_new = tc_titles_new[genres == 'Tragi-comédie']\n",
    "print(tc_dists_new.shape)\n",
    "\n",
    "#top_three_tragi-comedy_titles  = tc_titles_new[top_three_tc_new]\n",
    "print('\\n'.join([str(v) for v in tc_titles_new[top_three_tc_new]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-springfield",
   "metadata": {},
   "source": [
    "### Q4. Do you think that the profile must include all words appearing at least once in a play of the group? If no, how can we select a subset of the terms that must appear in a profile? Justify your choice.\n",
    "\n",
    "selecting the subset of each genre of atleast 50% of plays\n",
    "#### Result:\n",
    "No,No need to include all words in a profile but we can also obtain almost same result with the subset, Here, I compute with the subset of 50% terms. I observe slight reduction in the deviation of the comedie plays from .206 to .182 using the reduced document term matrix. We can examine the top 3 plays for each category remains almost the same compared to the document term matrix, with all the terms considered. \n",
    "\n",
    "#### Genre Comedy top 3 plays WITHOUT subset :\n",
    "L'ÉCOLE DES FEMMES, COMÉDIE.(1)\n",
    "LES MÉNECHMES, ou LES JUMEAUX, COMÉDIE(2)\n",
    "LA COMÉDIE SANS TITRE, COMÉDIE.(3)\n",
    "\n",
    "#### Genre Comedy top 3 plays WITH subset :\n",
    "LES MÉNECHMES, ou LES JUMEAUX, COMÉDIE(1)\n",
    "L'ÉCOLE DES FEMMES, COMÉDIE.(2)\n",
    "LA COMÉDIE SANS TITRE, COMÉDIE.(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hawaiian-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_comedy = pd.DataFrame(document_term_matrix[genres == 'Comédie'])\n",
    "dtm_comedy = np.array(dtm_comedy.loc[:,dtm_comedy.eq(0).mean().le(.5)])\n",
    "\n",
    "dtm_tragedy = pd.DataFrame(document_term_matrix[genres == 'Tragédie'])\n",
    "dtm_tragedy = np.array(dtm_tragedy.loc[:,dtm_tragedy.eq(0).mean().le(.5)])\n",
    "\n",
    "dtm_tragedy_comedy = pd.DataFrame(document_term_matrix[genres == 'Tragi-comédie'])\n",
    "dtm_tragedy_comedy = np.array(dtm_tragedy_comedy.loc[:,dtm_tragedy_comedy.eq(0).mean().le(.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "false-decline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtm_comedy shape:(310, 776),\n",
      "dtm_tragedy shape:(150, 1403),\n",
      "dtm_tragedy_comedy shape:(38, 1597)\n"
     ]
    }
   ],
   "source": [
    "print(\"dtm_comedy shape:{},\\ndtm_tragedy shape:{},\\ndtm_tragedy_comedy shape:{}\".format(dtm_comedy.shape, dtm_tragedy.shape, dtm_tragedy_comedy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "arranged-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_mean_subset = dtm_comedy.mean(axis=0)\n",
    "tr_mean_subset = dtm_tragedy.mean(axis=0)\n",
    "tc_mean_subset = dtm_tragedy_comedy.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dressed-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dists_subset, c_dists_subset, tc_dists_subset = [], [], []\n",
    "\n",
    "for aPlay in dtm_comedy:\n",
    "    c_dists_subset.append(cosine_distance(aPlay, co_mean_subset))\n",
    "\n",
    "for aPlay in dtm_tragedy:  #document_term_matrix[genres == 'Tragédie']\n",
    "    t_dists_subset.append(cosine_distance(aPlay, tr_mean_subset))\n",
    "\n",
    "for aPlay in dtm_tragedy_comedy:  #document_term_matrix[genres == 'Tragédie']\n",
    "    tc_dists_subset.append(cosine_distance(aPlay, tc_mean_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "signed-water",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean distance to subset of comédie vector:0.035, and Standard deviation:0.0182\n",
      "Mean distance to comédie vector:0.040, and Standard deviation:0.0206\n",
      "\n",
      "Mean distance to subset of Tragédie vector:0.027, and Standard deviation:0.0125\n",
      "Mean distance to Tragédie vector:0.030, and Standard deviation:0.0144\n",
      "\n",
      "Mean distance to subset of Tragi-comédie vector:0.022,and Standard deviation:0.0089\n",
      "Mean distance to Tragi-comédie vector:0.024,and Standard deviation:0.0092\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean distance to subset of comédie vector:{:.3f}, and Standard deviation:{:.4f}\".format(np.mean(c_dists_subset),np.std(c_dists_subset)))\n",
    "print(\"Mean distance to comédie vector:{:.3f}, and Standard deviation:{:.4f}\\n\".format(np.mean(c_dists),np.std(c_dists)))\n",
    "\n",
    "print(\"Mean distance to subset of Tragédie vector:{:.3f}, and Standard deviation:{:.4f}\".format(np.mean(t_dists_subset),np.std(t_dists_subset)))\n",
    "print(\"Mean distance to Tragédie vector:{:.3f}, and Standard deviation:{:.4f}\\n\".format(np.mean(t_dists),np.std(t_dists)))\n",
    "\n",
    "print(\"Mean distance to subset of Tragi-comédie vector:{:.3f},and Standard deviation:{:.4f}\".format(np.mean(tc_dists_subset),np.std(tc_dists_subset)))\n",
    "print(\"Mean distance to Tragi-comédie vector:{:.3f},and Standard deviation:{:.4f}\".format(np.mean(tc_dists),np.std(tc_dists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "whole-albuquerque",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LES MÉNECHMES, ou LES JUMEAUX, COMÉDIE\n",
      "L'ÉCOLE DES FEMMES, COMÉDIE.\n",
      "LA COMÉDIE SANS TITRE, COMÉDIE.\n"
     ]
    }
   ],
   "source": [
    "c_dists_subset = np.array(c_dists_subset)\n",
    "top_three_subset_c = c_dists_subset.argsort()[:3]\n",
    "c_titles_subset = np.array(titles)[genres == 'Comédie']\n",
    "print('\\n'.join(c_titles_subset[top_three_subset_c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "limited-honolulu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRÈNE, TRAGÉDIE\n",
      "MARIAMNE, TRAGÉDIE EN CINQ ACTES.\n",
      "LE COMTE DE WARWIK, TRAGÉDIE.\n"
     ]
    }
   ],
   "source": [
    "t_dists_subset = np.array(t_dists_subset)\n",
    "top_three_subset_t = t_dists_subset.argsort()[:3]\n",
    "t_titles_subset = np.array(titles)[genres == 'Tragédie']\n",
    "print('\\n'.join(t_titles_subset[top_three_subset_t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "focused-judgment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EURIMÉDON OU L'ILLUSTRE PIRATE. TRAGI-COMÉDIE.\n",
      "LA BRADAMANTE, TRAGI-COMÉDIE.\n",
      "DOM QUICHOTTE DE LA MANCHE, COMÉDIE.\n"
     ]
    }
   ],
   "source": [
    "tc_dists_subset = np.array(tc_dists_subset)\n",
    "top_three_subset_tc = tc_dists_subset.argsort()[:3]\n",
    "tc_titles_subset = np.array(titles)[genres == 'Tragi-comédie']\n",
    "print('\\n'.join(tc_titles_subset[top_three_subset_tc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-commodity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-invite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-surge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-corrections",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
